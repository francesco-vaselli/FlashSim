{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PLEASE NOTE THAT THIS IS STILL A WORK IN PROGRESS AND WILL BE UPDATED IN THE NEAR FUTURE","text":"<p>The following pages serve as an introduction to the ideas behind our FlashSim prototype, a ML based simulation framework for the needs of the CMS experiment at CERN.</p> <p>We can visualize the classical simulation pipeline (FullSim) as being broadly divided into three steps:</p> <ol> <li>Generation: the results from theoretical calculations, typically consisting in a list of final-state, stable particles;</li> <li>Simulation: the actual simulation of all the interactions with the detector submodules,  (e.g. due to the photoelectric effect, Compton scattering, bremsstrahlung, ionization, multiple scattering, decays, nuclear interactions, \\(\\dots\\) for each particle);</li> <li>Digitization and Reconstruction: the conversion to electronic readout and the passage through the hundreds of reconstruction algorithms (common step with real detector events), resulting in the RAW analysis objects.</li> </ol> <p>Sounds costly, doesn't it? What if we tried to use ML to skip the last two steps and maybe even generate data directly into the standard analysis format (NanoAOD)? See below:</p> <p></p> <p>Where we've also shown a competing approach, CMS FastSim.</p> <p>As a first proof-of-concept we realized two networks, one for generating Jets and the other for Muons. We started from the Gen-level information of an existing NanoAOD dataset, and generated a new, original and NanoAOD-like dataset. The basic steps are as follows:</p> <p></p> <p>Aside from a straightforward comparison between FullSim and FlashSim, this two objects allowed us to compare our results in a real-world scenario: the first steps of the CMS VBF \\(H \\rightarrow \\mu^+ \\mu^-\\) analysis.</p> <p>The rest of these pages are thus organized:</p> <ul> <li>Preprocessing: this section explains the extraction and the preprocessing steps for the jets and muons data, for both training and generation;</li> <li>Trainings: explains the architectures (Normalizing Flows are being used and will be introduced assuming basic ML knowledge), the training and all the juicy technicalities;</li> <li>Generation: explains the various generation loops used for the creation of the various datasets;</li> <li>Results: displays the results.</li> </ul>"},{"location":"generation/","title":"Generation","text":"<p>Change of behavior with Uproot update</p> <p>Since the release of Uproot 5.0, we can no longer obtain a multiindex pandas dataframe with events of different length with the sintax <code>df = tree.arrays(library=\"pd\", *args, **kwargs)</code> as done in the code used here. </p> <p>The new syntax to get the same behavior is <code>df = ak.to_dataframe(tree.arrays(library=\"ak\", *args, **kwargs))</code></p>"},{"location":"generation/#generating-synthetic-nanoaod-files","title":"Generating synthetic NanoAOD files","text":"<p>The following section explains the code used for generating synthetic NanoAOD files starting from the GEN content of a pre-existing NanoAOD. The basics steps are:</p> <ol> <li> <p>Extract the GEN info from the <code>.root</code> file using a <code>C++</code> macro executed directly into the <code>Python</code> code thanks to the <code>ROOT.gInterpreter.Declare</code> interpreter. This is the same code used for extracting the training data, but there is no matching as we want just the GEN info. The ouptut is saved to an intermediate file.</p> </li> <li> <p>Read the GEN information into various pandas dataframes with <code>Uproot</code>, get the single events structure (i.e. how many objects per events) to reconstruct the event later on. Additionally save global event information as well as some electron variables which have not been simulated and are needed for the analysis test. Finally, check for events without muons/jets/electrons and adjust the events structure accordingly.</p> </li> <li> <p>Generate the jets and muons data loading the trained models, adjust preprocessed outputs to get the physical quantities.</p> </li> <li> <p>Convert results to jagged <code>awkward arrays</code> to save them directly into a <code>.root</code> file with the correct <code>TTree</code> structure.</p> </li> </ol> <p>All the steps are repeated for each NanoAOD file in the dataset, by calling the <code>nbd</code> (Nano Builder) function in a for loop.</p> <p>Steps 2 and 4 required a careful handling of the events structure and are discussed below in greater detail.</p>"},{"location":"generation/#getting-the-events-structure","title":"Getting the events structure","text":"<p>Let's have a look at code of the reading and structuring for muons:</p> <pre><code>    # read muon data to df\n    dfm = tree.arrays(muon_cond, library=\"pd\").astype(\"float32\").dropna()\n    dfm = dfm[~dfm.isin([np.nan, np.inf, -np.inf]).any(1)]\n    phys_pt = dfm[\"MGenMuon_pt\"].values  # for later rescaling\n    print(phys_pt.shape)\n\n    # preprocess conditioning variables\n    dfm[\"MGenMuon_pt\"] = dfm[\"MGenMuon_pt\"].apply(\n        lambda x: np.log(x)\n    )  # for conditioning\n    dfm[\"MClosestJet_pt\"] = dfm[\"MClosestJet_pt\"].apply(lambda x: np.log1p(x))\n    dfm[\"MClosestJet_mass\"] = dfm[\"MClosestJet_mass\"].apply(lambda x: np.log1p(x))\n    dfm[\"Pileup_sumEOOT\"] = dfm[\"Pileup_sumEOOT\"].apply(lambda x: np.log(x))\n    dfm[\"Pileup_sumLOOT\"] = dfm[\"Pileup_sumLOOT\"].apply(lambda x: np.log1p(x))\n    dfm = dfm[~dfm.isin([np.nan, np.inf, -np.inf]).any(1)]\n    print(dfm)\n    # crucial step: save original multiindex structure to restructure outputs later\n    muons_ev_index = np.unique(dfm.index.get_level_values(0).values)\n    print(muons_ev_index)\n    events_structure_muons = (\n        dfm.reset_index(level=1).index.value_counts().sort_index().values\n    )\n    print(len(events_structure_muons))\n    print(sum(events_structure_muons))\n\n    # reset dataframe index for performing 1to1 generation\n    dfm.reset_index(drop=True)\n</code></pre> <p>The variable <code>muons_ev_index</code> stores the event number. This is needed because some events may be missing muons and will not be listed: if event 3 has no muons the list will be <code>[0, 1, 2, 4, ..., 1287960]</code>.  </p> <p>The <code>events_structure_muons</code> variable is a list of the number of muons in each event (i.e. <code>[3, 2, ..., 1, 2]</code>), ordered in the same way as <code>muons_ev_index</code>. Both are being extracted directly from the pandas multiindex structure which is generated directly from Uproot. This has the advantage of avoiding needles looping and counting over the events.</p> <p>Then, because we need to include 0s where there are no muons in order to restructure the final events, we are manually putting them in the correct positions:</p> <pre><code>    # adjust structure if some events have no muons\n    # dfe = dataframe event containing global info for each event (and thus all events)\n    zeros = np.zeros(len(dfe), dtype=int)\n    print(len(muons_ev_index), len(events_structure_muons))\n    # puts number of muons in corresponding event, otherwise leave 0\n    np.put(zeros, muons_ev_index, events_structure_muons, mode=\"rise\")\n    events_structure_muons = zeros\n    print(events_structure_muons.shape, events_structure_muons)\n    print(sum(events_structure_muons))\n</code></pre>"},{"location":"generation/#structuring-the-results","title":"Structuring the results","text":"<p>Once we have the outputs of our networks, we simply restructure them into a jagged awkward array and save it to file:</p> <pre><code>    # get a muon collection with the original event structure and branches\n    # muon_names = branches names\n    # totalm = final output for muons\n    to_ttreem = dict(zip(muon_names, totalm.T))\n    to_ttreem = ak.Array(to_ttreem)\n    to_ttreem = ak.unflatten(to_ttreem, events_structure_muons)\n\n    # once we have all objects save file\n    # use uproot recreate to save directly akw arrays to .root file\n    new_path = str(os.path.join(new_root, file_path))\n    new_path = os.path.splitext(new_path)[0]\n    with uproot.recreate(f\"{new_path}_synth.root\") as file:\n        file[\"Events\"] = {\n            \"Jet\": to_ttreej,\n            \"Muon\": to_ttreem,\n            \"Electron\": to_ttreel,\n            \"event\": to_ttreee.event,\n            \"run\": to_ttreee.run,\n        }\n\n    return\n</code></pre>"},{"location":"generation/#upsampling","title":"Upsampling","text":"<p>Because we are generating events so fast, the production of new GEN samples becomes the next speed bottleneck. We investigated the upsampling procedure, that is sampling multiple times from the same GEN sample, as a way to mitigate the bottleneck. The results and statistical handling are discussed in the next section; here we discuss the changes to the generation code.</p> <p>We used the following strategy:</p> <pre><code>    # main difference from 1to1 case: we need to produce \n    # an upsampled index for saving the right topology later\n    numb_ev = dfm.index.get_level_values(0).values\n    # use list comprehension to save the new event list\n    # (if UPSAMPLING_FACTOR=1 GO from [0, 1, 2] to [0, 1, 2, 3, 4, 5])\n    l = [numb_ev + n * (numb_ev[-1] + 1) for n in np.arange(0, UPSAMPLE_FACTOR)]\n    numb_ev = np.concatenate(l, axis=0)\n    # main upsampling idea: concatenate multiple copies \n    # of the original df\n    dfm = pd.concat([dfm] * UPSAMPLE_FACTOR, axis=0)\n    numb_sub_ev = dfm.index.get_level_values(1).values\n    up_index = pd.MultiIndex.from_arrays(\n        [numb_ev, numb_sub_ev], names=[\"event\", \"object\"]\n    )\n    dfm = dfm.set_index(up_index)\n</code></pre> <p>We defined a global <code>UPSAMPLE_FACTOR = n</code> defining how many throws should be performed for each event. Then, we created a new event index repeating the original event structure n times. We concatenated the original dataframe n times and applied the new structure. </p> <p>In this way, each event is repeated exactly n times, one repetition at a time in the original ordering.</p>"},{"location":"preprocessing/","title":"Preprocessing","text":""},{"location":"preprocessing/#what-we-did-and-why-we-did-it","title":"What we did and why we did it","text":"<p>We processed the NanoAOD files and extracted all the Jet objects matched to a GenJet object and the Muon objects matched to a GenMuon across all the events in the file. The output of the extraction step is another <code>.root</code> file containing just the selected objects. We need this 1-to-1 matching because we want to pass the RECO objects as targets and the corresponding Gen objects as conditioning to the models (see Trainings section), that is we want the output to depend on the physical inputs of the various possible processes.</p> <p>The resulting file is still organized according to the Events structure (that is, a single event may contain an arbitrary number of jets and muons). Besides, we know that many machine learning algorithms work best when specific distributions are preprocessed according to specifc criteria. Normalizing Flows are no exception. Specifically, there are four key features which should be accounted for and modified through preprocessing before training:</p> <ol> <li> <p>Because NF are learning actual pdfs, large gaps between values of the distribution may disturb training and trick the network to bridge the extremes of the distribution by creating spurious samples in the gap. When possible, the gaps should be reduced and the values packed closer together;</p> </li> <li> <p>As NF assume a continuous and differentiable pdf, they are not well suited to deal with discrete distributions. Thus, we should apply a process known as dequantization, that is applying some sort of smearing to the discrete values to make them similar to those sampled from a continuous distribution;</p> </li> <li> <p>For similar reasons as before, when possible it would be beneficial to widen and normalize steeply falling distributions through invertible transforms such as log(x). If well separated, eventual peaks may be dequantized as well;</p> </li> <li> <p>Finally, we opted for saturating long tails of distributions to some limiting values, in order to make it easier for the model to learn the pdf in the more populated region.</p> </li> </ol> <p>Apart from possibly dequantization, we stress that all of this transformations were implemented to make training easier but are not strictly necessary--the models revealed themselves as powerful enough to deal with complex, sharply peaked, long tailed distributions. However, having already implemented the preprocessing pipeline and because it did not introduce a big overhead in the procedure, we decided to keep it for the present work. An example of one of the possible preprocessing operations is shown in the following figure:</p> <p></p> <p>Sharply peaked distribution are being converted to more broad ones during the preprocessing step. In this example the <code>ip3d</code> variable, the 3D impact parameter of the \\(\\mu\\) w.r.t. the primary vertex, gets transformed as log(<code>ip3d</code>+0.001).</p> <p>All of these transforms may be implemented with a clear and natural syntax in the <code>Python</code> programming language, specifically thanks to the <code>pandas</code> package, which implements a convenient dataframe structure.</p>"},{"location":"preprocessing/#extraction-details","title":"Extraction details","text":"<p>First, we extract the Gen and RECO objects from an existing NanoAOD file. With the use of <code>C/C++</code> code (e.g. muons_extraction.cpp ) for the <code>ROOT</code> data analysis framework, this operation can be performed rather quickly thanks to the compiled nature of the language being used and the powerful <code>ROOT::RDataFrame()</code> class, offering a modern, high-level interface for the manipulation of data stored in a NanoAOD <code>TTree</code>, as well as <code>multi-threading</code> and other low-level optimizations.</p> <p>The basic idea for the extraction process is to define some functions and using the <code>df.Define()</code> method for calling the function on the selected rows and columns</p> <p><pre><code>auto DeltaPhi(ROOT::VecOps::RVec&lt;float&gt; &amp;Phi1, ROOT::VecOps::RVec&lt;float&gt; &amp;Phi2) {\n    /* Calculates the DeltaPhi between two RVecs\n    */\n    auto size = Phi1.size();\n    ROOT::VecOps::RVec&lt;float&gt; dphis;\n    dphis.reserve(size);\n    for (size_t i = 0; i &lt; size; i++) {\n        Double_t dphi = TVector2::Phi_mpi_pi(Phi1[i]-Phi2[i]);\n        dphis.emplace_back(dphi);\n    }\n    return dphis;\n    }\n\n//stuff \n\n// f is NanoAOD file\nROOT::RDataFrame d(\"Events\",f);\n\n// create first mask\nauto d_def = d.Define(\"MuonMask\", \"Muon_genPartIdx &gt;=0\").Define(\"MatchedGenMuons\", \"Muon_genPartIdx[MuonMask]\");\n\n// The main rdataframe, LAZILY defining all the new processed columns.\n// here we show the extraction of Delta Phi between gen and reco muons\nauto d_matched = d_def\n            .Define(\"MMuon_filteredphi\", \"Muon_phi      [MuonMask]\")\n            .Define(\"MMuon_phiMinusGen\", DeltaPhi,  {\"MMuon_filteredphi\", \"MGenMuon_phi\"})\n            .//other Define()s\n\n// finally process columns and save to .root file\nd_matched.Snapshot(\"MMuons\", \"MMuons.root\", col_to_save);\n</code></pre> The output of the extraction step is another .root file containing just the selected objects. </p>"},{"location":"preprocessing/#ok-but-what-do-we-want-to-extract","title":"Ok, but what do we want to extract?!","text":"<p>Please read this only if you are interested in the full list of targets and conditioning variables--it is quite a lengthy section and not that useful for later.</p> <p>The idea is being able to directly generate correctly distributed Jet objects starting from noise, for stochasticity,  but also from the values of a corresponding GenJet, as a physical-informed input for the network (a process known as conditioning): knowing just the generator-level information of some process, we are going to skip the Simulation, Digitization and Reconstruction steps.</p> <p>Because of the large number of variables, we selected a meaningful subset, containing all the necessary information for our test analysis.</p>"},{"location":"preprocessing/#jet-conditioning","title":"Jet conditioning","text":"<p>First of all, we selected the following 14 GenJet variables for conditioning the generation: </p> <ol> <li>The physical properties of the GenJet, that is \\(\\eta\\), \\(\\phi\\), \\(m_j\\), \\(p_T\\), and the </li> <li> <p>Parton and Hadron Flavour, giving the flavour content of a jet as containing a specific quark or some gluons;</p> </li> <li> <p>Variables correlated with the rest of the event, as the actual properties of a jet are expected to be influenced by other objects such as muons. Computing the \\(\\Delta\\)R separation between the GenJet and the GenMuons present in the event, we selected the first and second closest muons, and we computed the following quantities for each one:</p> </li> <li> <p>\\(\\Delta\\)R, giving the separation from the GenJet, \\(\\Delta \\eta\\), the \\(\\eta\\) difference from the GenJet, \\(\\Delta p_T\\), the \\(p_T\\) difference from the GenJet, \\(\\Delta \\phi\\), the \\(\\phi\\) difference from the GenJet;</p> </li> <li> <p>If no GenMuons were present within a cone of \\(\\Delta\\)R = 0.5 from the GenJet, the corresponding values were set to a user-defined maximum.</p> </li> </ol>"},{"location":"preprocessing/#jet-targets","title":"Jet targets","text":"<p>Then, we selected the following 17 target reconstructed variables for the matched reconstructed Jet objects:</p> <ol> <li> <p>The physical properties of the Jet with regard to the ones of the matched GenJet: \\(\\Delta\\eta\\), the \\(\\eta_{reco} - \\eta_{gen}\\) difference , \\(\\Delta\\phi\\), the \\(\\phi\\) difference, \\(R_m\\), the ratio of the jet and GenJet masses, \\(R_{p_T}\\), the ratio of \\(p_T\\)s. This was done because the Simulation and Reconstruction steps are expected to introduce corrections w.r.t. the GenJet distributions, easier to learn when considering these quantities. As an additional variable, the Jet Area, a measure of its susceptibility to radiation, like pile-up or underlying event, was added as well;</p> </li> <li> <p>Some of the btag discriminant variables b-tagging and c-tagging algorithms scores: btagCMVA, btagCSVV2, btagDeepB, btagDeepC, btagDeepFlavB and btagDeepFlavC, which indicate with a score ranging from 0 to 1 whether the Jet contains the respective quark or not, a very significant information for performing event selection during an analysis. Some values may be offsetted to -1 to indicate that the corresponding tagging algorithm has failed to assign a score to the event;</p> </li> <li> <p>The bRegCorr, the \\(p_T\\) correction for b-jet energy regression, as the presence of neurinos due to semi-leptonic decays in the jets coming from b quarks can result in underestimated jet energy measurements;</p> </li> <li> <p>The qgl score for the Quark vs Gluon likelihood discriminator, which is employed as most of the interesting physics channels studied at the LHC involve hadronic jets initiated by quarks, while dominant backgrounds often arise from QCD events, where jets are generally produced from gluons;</p> </li> <li> <p>The jetID and puID ID flags indicating relevant characteristics of the jet as well as the event noise and pile-up.</p> </li> </ol>"},{"location":"preprocessing/#muons-conditioning","title":"Muons conditioning","text":"<p>For muons we performed the same procedure, taking only those muons matching to GenMuon objects (a GenParticle object with pdgId value of +-13). </p> <p>We selected 30 GenMuon variables for conditioning:</p> <ol> <li> <p>The physical properties of the GenMuon, that is \\(\\eta\\), \\(\\phi\\), Charge and \\(p_T\\);</p> </li> <li> <p>The 14 GenParticle status flags, a series of \\statusFlags stored bitwise, with each bit having a different physical interpretation such as isTauDecayProduct, fromHardProcess, etc. ;</p> </li> <li> <p>Variables correlated with the rest of the event, as the actual properties of a muon are expected to be influenced by other objects such as jets. Computing the \\(\\Delta\\)R separation between the GenMuon and the GenJets present in the event, we selected the first closest GenJet, and we computed the following quantities:</p> <ul> <li>\\(\\Delta\\)R, giving the separation from the GenJet, \\(\\Delta\\eta\\), the \\(\\eta_{muon} - \\eta_{jet}\\) difference, \\(R_{p_T}\\), the ratio of \\(p_T\\)s, \\(\\Delta\\phi\\), the \\(\\phi\\) difference, and finally the \\(m_j\\) of the closest GenJet;</li> </ul> </li> <li> <p>A series of 6 Event level variables regarding pile-up: Pileup_gpudensity, the Generator-level PU vertices/mm,Pileup_nPU, the number of pile-up interactions that have been added to the event in the current bunch crossing, Pileup_nTrueInt, the true mean number of the poisson distribution for this event from which the number of interactions each bunch crossing has been sampled, Pileup_pudensity, PU vertices/mm, Pileup_sumEOOT, the number of early out of time pile-up and Pileup_sumLOOT, the number of late out of time pile-up;</p> </li> </ol>"},{"location":"preprocessing/#muons-targets","title":"Muons targets","text":"<p>Then we selected 22 target variables for the Muon objects:</p> <ol> <li> <p>The physical properties of the muon with regard to the ones of the matched GenMuon: \\(\\Delta\\eta\\), the \\(\\eta_{reco} - \\eta_{gen}\\) difference , \\(\\Delta\\phi\\), the \\(\\phi\\) difference, \\(R_{p_T}\\), the ratio of Gen vs reco \\(p_T\\)s. This was done because the Simulation and Reconstruction steps are expected to introduce corrections w.r.t. the GenMuon distributions, easier to learn when considering these quantities. As an additional variable, the \\texttt{ptErr}, the \\(p_T\\) error for the muon track, was selected as well;</p> </li> <li> <p>Six impact parameters with respect to the primary vertex, related to the impact parameter d, defined at the distance between the daughter particle trajectory and the mother particle production point. It can be defined by first minimizing the distance on a plane, definig dxy, dxyErr and then minimize on the remaining axis dz, with its dzErr. Alternatively, we can minimize the distance directly in 3 dimensions, obtaining the 3D impact parameter ip3d and its significance sip3d, all expressed in cm;</p> </li> <li> <p>Some Boolean flags expressing relevant properties of the object as identified by reconstruction algorithms: isGlobal, isPFcand, identifying the muon as a Particle Flow candidate, isTracker;</p> </li> <li> <p>A series of isolation variables returned by the Particle Flow algorithm: pfRelIso03_all, pfRelIso03_chg and pfRelIso04_all;</p> </li> <li> <p>The variables related to the closest jet: jetPtRelv2, indicating the relative momentum of the lepton with respect to the closest jet after subtracting the lepton and jetRelIso, the relative isolation in matched jet;</p> </li> <li> <p>A series of ID scores: mediumID, softMVA scores and their cut-based Boolean IDs softMVAId, softId;</p> </li> </ol>"},{"location":"results/","title":"Results","text":"<p>This long section serves to present in a comprehensive way the results obtained.</p> <p>To perform a sound and reasonable comparison, we extract the Gen-values for conditioning from \\(10^{5}\\) t\\(\\overline{\\text{t}}\\) samples coming from an unseen test set for jets and from the validation set (which was not used for training but just for evaluating the loss over time) for muons. We then generate new analysis samples using FlashSim and starting from the same Gen-values, to get a one-to-one correspondence between the them and FullSim samples.</p> <p>We performed two main types of comparison on the obtained samples: we compared the 1-d distribution and the 2-d correlations for any pair of variables. We inspected the latter visually thanks to contour plots, but we wanted to have a precise measure for the similarity of the empirical distributions between two samples. We thus choose the Wasserstein distance, defined as:</p> \\[W_1(u, v) = \\inf_{\\pi \\in \\Gamma(u, v)}\\int_{\\mathbb{R}\\times\\mathbb{R}}|x-y|d\\pi(x,y) = \\int_{-\\infty}^{+\\infty} |U - V|\\] <p>where \\(\\Gamma(u, v)\\) is the set of (probability) distributions on \\(\\mathbb{R}\\times\\mathbb{R}\\) whose marginals are \\(u\\) and \\(v\\) on the first and second factors respectively, and \\(U\\), \\(V\\) are the respective CDFs. Intuitively, if each distribution is viewed as a unit amount of earth (soil), the metric is the minimum cost of turning one pile into the other, which is assumed to be the amount of earth that needs to be moved times the mean distance it has to be moved, and thus this metric is also know informally as the earth mover distance.</p>"},{"location":"results/#jets-results","title":"Jets Results","text":""},{"location":"results/#1d","title":"1D","text":"<p>We show in the following figure four 1-d distributions out of the total of 17 target variables obtained for jets. We emphasize once more that the model actually learned to generate the 17 values simultaneously, preserving the correct correlations as well as producing convincing distribution.</p> <p>Regarding the distributions, we observe that the model has correctly learned all the multi-modal, sharply peaked tagging distributions with Wasserstein scores of the order of \\(0.001\\), testifying good convergence. The log scale of btagDeepB actually shows an instance of bridging, where a small set of values were generated between two separate peaks. Single-mode distributions such as ptRatio have been larned as well, as were the Ids thanks to dequantization. The jetId outputs were rounded to the closest value between 0, 2 and 6, the only admissible ones.</p> <p>Finally, we also observe a worse performance on two distributions: bRegCorr, a rather simple, skewed one-mode distribution which is expected to improve with further training (current Wasserstein distance is \\(\\approx\\) 0.02), and nConstituents. The latter result is probably in stronger disagreement because the target actually consists of integer values--as we discussed before, the NF approach expects continuous distributions, and so the model performs bridging in an attempt to obtain a reasonable continuous distribution. However, it has been observed in previous trainings for similar architectures that the model is actually capable of partially overcoming this limitation by brute force alone: if left in training for long enough it may eventually learn to output values close to the integer ones.</p> <p> </p>"},{"location":"results/#jets-correlations","title":"Jets correlations","text":"<p>The correlations between jets variables, inspected visually, show good agreement with those from FullSim. The following figures shows the highly non-trivial correlations between the tagging distributions, with quantiles plotted at 0.5, 0.9, 0.99. The same choice for quantiles has been adopted for all the following figures.</p> <p></p> <p>We can also observe in the following figures how the models have learned to capture the correlations between the qgl score, which is correctly correlated to the number of constituents as a lower number of constituents is expected for the u, d, s quarks when compared to gluons. Additionally, correlations between the physical p\\(_T\\) and mass distributions, obtained from the original p\\(_T\\)Ratio and massRatio outputs of the network, have been learned as well.</p> <p> </p>"},{"location":"results/#muons-results","title":"Muons results","text":""},{"location":"results/#1d_1","title":"1D","text":"<p>For the muons, we obtained similar results--good, convincing general convergence and correlations apart from a subset of the target variables. It should be noted that a larger number of target variables for this case were actually Boolean Ids, and as discussed before were approached through dequantization. The following figures shows 4 distributions out of 22 target variables. Aside from good convergence on the firs two, we can observe that for a series of them, such as the impact parameters errors dxyErr and dzErr the training is complicated by the fact that the NanoAOD format stores the variables in a low-precision format: this is reflected by the jagged structure in the plot for FullSim and it causes the model to perform bridging to reach convergence.</p> <p> </p>"},{"location":"results/#correlations","title":"Correlations","text":"<p>Finally, as a last example of correlations, we show in the following that the model has actually learned to capture complex correlations such as the ones between the impact parameter ip3d and the quantity \\(\\sqrt{\\texttt{dxy}^2 + \\texttt{dz}^2}\\), which is closely related to the definition of the impact parameter itself.</p> <p></p>"},{"location":"results/#conditioning","title":"Conditioning","text":"<p>Another extremely important feature of our approach is the desired ability to obtain specific results starting from certain Gen-level inputs, a characteristic we called conditioning. The idea is that we want to learn not just \\(p^*_x(\\mathbf{x})\\), but \\(p^*_x(\\mathbf{x}|\\text{Gen})\\).</p> <p>We can readily see that this is possible by focusing on specific results obtained for the jets model. The following shows that the final, NanoAOD level reconstructed p\\(_T\\) is correctly correlated to the GenJet p\\(_T\\) for both FullSim and FlashSim: as we would expect the Gen-p\\(_T\\) is crucial in determining the final-state p\\(_T\\). What is more, in the same figure we also show the profile histogram and RMS (\\(\\sigma_{p_T}\\)/p\\(_T\\)) for the GenJet p\\(_T\\) versus the p\\(_T\\)Ratio. As expected, not only does the p\\(_T\\)Ratio decrease as the GenJet p\\(_T\\) increases (highly energetic jets have a reconstructed p\\(_T\\) closer to the Gen-value), but the RMS correctly decreases as well, as constant terms in the p\\(_T\\) resolution due to pile-up are divided by bigger terms as GenJet p\\(_T\\) increases.</p> <p> </p> <p>Additionally, because the partonFlavour conditioning variable allow us to specify the quark content of a jet, we can study how related quantities depend on this input. As a key example, we study the behaviour of the btagDeepB b-tagging distribution as we vary the parton input for the jet generation. The next figures show how the distribution changes according to the ground truth value specified as input: as expected, jets being conditioned with a b content present higher values of b-tagging, with a sharp peak at one, while those coming from u, d, s are clearly peaked around smaller values. Now we could think of defining a threshold and assign a reconstructed b content to all those jets higher than that value. We would naturally mistag some events, leading us to define a flase-positive ratio and a true-positive one. A standard figure of merit for these cases is the Receiving operating characteristic (ROC) curve, which plots the TPR against the FPR for all possible threshold choices. The last figure shows it for our model in log scale, showing minimal deviations from the target FullSim curve.</p> <p> </p> <p>Because our results are not as close to FullSim as it was for 2-d correlations, we would like to compare them with other competing approaches to asses the goodness of our own methodology. In order to do so, for a previous training with a lower number of jet target variables, presented at the CMS Machine learning Forum of April 2022, we compared the ROC curves between FullSim, FastSim and FlashSim on a \\(10^{6}\\) t\\(\\overline{\\text{t}}\\) samples set (not previously seen during training). Results are shown in the next Figure. We can see that while the ROC between our approach and FullSim is actually indistiguishable for TPR higher than 0.8, the FastSim ROC completely overshoots the target, due to oversimplifications in the simulation approach. With longer training times and additional loss terms addressing this type of conditioning, which is currently not considered by the model loss function, we are confident that the performance of FlashSim could be improved even more.</p> <p></p>"},{"location":"results/#speed","title":"Speed","text":"<p>A crucial result obtained is the generation speed: for both jets and muons we managed to generate samples in batches of \\(10^{4}\\) in \\(\\approx\\) 0.3 seconds each, corresponding to a generation speed of raw samples of about 33,300 samples per second (33 kHz) meaning a six orders of magnitude speedup when compared to FullSim and four orders of magnitude speedup when compared to FastSim! Even considering possible reduction due to preprocessing and data loading, this result testify to the potential of the current methodology to completely redefine our approach to event simulation, at least at the NanoAOD level.</p> <p>What is more, the \\(10^{4}\\) batch size for generation was limited only by the VRAM of the GPU being used, meaning that more powerful GPUs, ideally working in parallel, could achieve even faster generation times.</p>"},{"location":"results/#results-on-unseen-processes","title":"Results on unseen processes","text":"<p>We actually extended the use of the models to unseen, different physical processes: Drell-Yan two-jets (DY), Electroweak two-muons two-jets (EWK LLJJ) and two Signal (H\\(\\rightarrow\\mu^+\\mu^-\\)) datasets were processed as well and stored for the comparison of the next chapter. Some results, are showed below and emphasize how our approach has correctly learned to simulate the interaction and reconstruction of the CMS detector, giving consistent results independently from the input process.</p> <p> </p>"},{"location":"results/#benchmark-analysis","title":"Benchmark analysis","text":"<p>Having described in detail our innovative approach to event simulation, and having applied it to generated events for which we have the FullSim sample, we decided to repeat the basic steps of a recent analysis to demonstrate the feasibility of our model in a real-case scenario.</p>"},{"location":"results/#the-higgs-decay-into-two-muons","title":"The Higgs decay into two muons","text":"<p>We generated a FlashSim dataset from the Gen-level information of the existing NanoAOD FullSim datasets for the different processes discussed before, that is:</p> <ol> <li>The t\\(\\overline{\\text{t}}\\) inclusive production (also used in training);</li> <li>The DY+2J process;</li> <li>The EWK production of \\(\\mu\\mu\\)+2J;</li> <li>The Higgs VBF production, with the Higgs decaying into pairs of \\(\\mu\\).</li> </ol> <p>We then performed the preliminary selection steps of the analysis presented in the analysis, specifically that of VBF Channel of H\\(\\rightarrow\\mu^+\\mu^-\\), for the reasons discussed previously. The objective was to verify that the selected objects distributions were close enough to those obtained from FullSim.</p>"},{"location":"results/#event-selection","title":"Event selection","text":"<p>First of all, we select muons as follows:</p> <ol> <li>pfRelIso04_all\\(= \\sum_{\\Delta R(PF_i, \\mu)&lt;0.4}p_T^i/p_T^{\\mu}&lt;0.25\\) (isolated);</li> <li>Muons passing the \\emph{medium} muon Id algorithm;</li> <li>\\(p_T^{\\mu}&gt;20\\) GeV;</li> <li>\\(|\\eta_{\\mu}|&lt;2.4\\).</li> </ol> <p>These are all features we would expect from a pair of muons decaying from a Higgs. An event is also required to have at least two opposite charged muons.</p> <p>In a similar way, we select the jets as those passing the following cuts:</p> <ol> <li>\\(p_T^{jet}&gt;25\\) GeV </li> <li>Additionally, for \\(p_T^{jet}&lt;50\\) GeV we require it to pass the pile-up Id algorithm;</li> <li>Jets passing the jet Id algorithm;</li> <li>\\(|\\eta_{jet}|&lt;4.7\\);</li> <li>We also require that jets do not overlap with muons within a \\(\\Delta R\\leq0.4\\) cone.</li> </ol> <p>A VBF candidate event is required to have at least two jets respecting the previous properties, one with \\(p_T&gt;35\\) GeV, the other with \\(p_T&gt;25\\) GeV, an invariant mass of the leading jet pair \\(m_{jj}&gt;400\\) GeV and a separation between the leading jets of \\(\\Delta\\eta&gt;2.5\\). Selected events are further grouped into two independent categories. Events in which the two muons form an invariant mass between 115 and 135 GeV belong to the signal region (VBF-SR), which is enriched in signal-like events. Events with 110 &lt; \\(m_{\\mu\\mu}\\) &lt; 115 GeV or 135 &lt; \\(m_{\\mu\\mu}\\) &lt; 150 GeV belong to the mass sideband region (VBF-SB), which in the full analysis has been used as a control region to estimate the backgroung.</p> <p>For each selected event we define the new, derived quantities that help discriminating the Higgs signal from the SM processes that represent a background for this analysis. Some crucial ones are:</p> <ol> <li>The reconstructed Higgs-candidate, with a 4-momentum given by the sum of the two four-vectors of the selected muons;</li> <li>Observables sensitive to \\(p_T\\) and angular correlations between muons and jets: </li> </ol> <p>The \\(p_T\\)-balance ratio, defined as:</p> \\[ R(p_T) = \\frac{|\\mathbf{p_T}^{jj}+\\mathbf{p_T}^{\\mu\\mu}|}{p_T(j_1) + p_T(j_2) + p_T^{\\mu\\mu}} \\] <p>and the Zeppenfeld variable \\(z^*\\), defined from the rapidity y as:</p> \\[z^* = \\frac{y_{\\mu\\mu} - (y_{j_1} + y_{j_2})/2}{|y_{j_1} - y_{j_2}|}\\] <ol> <li>The azimuthal angle (\\(\\phi_{CS}\\)) and the cosine of the polar angle (\\(\\cos\\theta_{CS}\\)) computed in the dimuon Collins\u2013Soper rest frame.</li> </ol> <p>The next Figure shows the \\(R(p_T)\\) and the \\(\\log(z^*)\\) for the Signal and the DY Background process, emphasizing how these quantities can be used to discriminate between the two. The Figure also introduces the FullSim vs FlashSim comparison and will be referenced again in the following.</p> <p> </p>"},{"location":"results/#a-dnn-for-event-classification","title":"A DNN for event classification","text":"<p>The CMS Collaboration used a deep neural network (DNN) multivariate discriminant, trained to distinguish the expected signal from background events using kinematic input variables that characterize the signal and the main background processes in the VBF-SR. The signal is then extracted from a binned maximum-likelihood fit to the output of the DNN discriminator simultaneously in the VBF-SR and the VBF-SB regions. </p> <p>The DNN used in the final analysis has been tested on the FlashSim samples, with the final weights and parameters resulting from the trainings already performed by the authors of the original paper on the FullSim dataset. We tested the network on our FlashSim data to compare the ouput with the one on the FullSim datasets used in the analysis and taken as Gen-level truth for generating our samples.</p> <p>The network takes as input 25 variables. The first 23 are listed below:</p> <ol> <li> <p>Six variables associated with production and decay of the dimuon pair: its mass \\(m_{\\mu\\mu}\\), the absolute and relative mass resolutions \\(\\Delta m_{\\mu\\mu}\\), \\(\\Delta m_{\\mu\\mu}/m_{\\mu\\mu}\\), its momentum \\(p_T^{\\mu\\mu}\\) and its logarithm, the pseudorapidity \\(\\eta_{\\mu\\mu}\\);</p> </li> <li> <p>The azimuthal angle (\\(\\phi_{CS}\\)) and the cosine of the polar angle (\\(\\cos\\theta_{CS}\\)), the \\(p_T\\)\\emph{-balance ratio} \\(R(p_T)\\) and the logarithm of the Zeppenfeld variable \\(z^*\\);</p> </li> <li> <p>The vector components of the leading jets, \\(p_T(j_1)\\), \\(\\eta(j_1)\\), \\(\\phi(j_1)\\), \\(p_T(j_2)\\), \\(\\eta(j_2)\\), \\(\\phi(j_2)\\), and their QGL scores, \\(QGL(j_1)\\), \\(QGL(J_2)\\), since jets in signal events are expected to originate from quarks, whereas in the DY process they can also be initiated by gluons;</p> </li> <li> <p>Key variables referring to the dijet system: its mass \\(m_{jj}\\) and \\(\\log(m_{jj})\\), the pseudorapidity distance between the two jets \\(\\Delta \\eta_{jj}\\);</p> </li> <li> <p>The minimum distance in pseudorapidity of the Higgs candidate with the two leading jets \\(\\min(\\eta(\\mu\\mu, j_1),\\eta(\\mu\\mu, j_2))\\);</p> </li> <li> <p>The data taking year (set to 2018 for both FullSim and FlashSim samples).</p> </li> </ol> <p>Additionally, the VBF signal events are expected to have suppressed hadronic activity in the rapidity gap between the two leading jets. This feature is exploited by considering soft jets in the event that are defined by clustering, via the anti-\\(k_T\\) jet-clustering algorithm with a distance parameter of 0.4, charged particles from the primary interaction vertex excluding the two identified muons and those associated with the two VBF jets. The soft jets are required to have \\(p_T&gt;5\\) GeV. The number of soft jets in an event, \\(N^{\\text{soft}}_5\\), as well as the scalar sum of their transverse momenta, \\(H^{\\text{soft}}_{(2)T}\\), are used as additional input variables.  Because soft activity depends upon the presence of additional charged particles, which we have not simulated in the present FlashSim prototype, we resorted to fixing the values of these two variables to \\(N^{\\text{soft}}_5=0\\) and \\(H^{\\text{soft}}_{(2)T}=1.0\\) GeV. As we are interested in performing a comparison of the DNN output for FullSim and FlashSim, using fixed values in the evaluation of both does not bias the results.</p>"},{"location":"results/#fullsim-vs-flashsim","title":"FullSim vs FlashSim","text":"<p>We observe good results on distributions directly related to the simulated targets of FlashSim. The next Figure shows the pfRelIso_04_all for lead muons passing the initial selection, which presents small deviations when compared to the FullSim sample, despite the lower number of FlashSim muons passing the selection. The bottom panel shows the ratio between the FlashSim and the FullSim sample, were the chosen convention here and in the following has been to always divide by the FullSim.</p> <p></p> <p>However, for jets, the agreement is not as good as for muons. The next figure shows that the \\(p_T\\) for the second selected jet is not as high for FlashSim jets as it is for FullSim ones. We tried to explain this result by remembering that our current prototype of FlashSim is missing fakes jets due to noise and pile-up, present in the other sample. In principle, higher-\\(p_T\\) fake jets may be selected in place of the second event jet for some of the FullSim samples, explaining the deviation observed. In fact, fake jets have usually low-\\(p_T\\), under 50 GeV, and we can see that our distribution is perfectly overlapping at high-\\(p_T\\).</p> <p></p> <p>The results related to angular distributions also show a good performance. We showed above how the histograms for the \\(R(p_T)\\) and the \\(\\log(z^*)\\)  of the Higgs vs DY processes, to show how these variables can be discriminant in distinguishing between signal and background. At the same time, we can see how FlashSim correctly reproduces the Signal versus Background differences.</p> <p>We also show the outputs of the VBF DNN discriminator network for each single process, which was used as the fit function for the real analysis. The FlashSim predictions are still very close to the FullSim ones, a crucial result for assessing the potential for real-world analysis applications.</p> <p> </p> <p>An even greater accuracy may be obtained when a FullSim sample is already available and we need alternative samples for estimating systematic uncertainties, e.g.  different theoretical variations for the same process. This is the case, for example, for the two samples of the Higgs signal, which differ in the theoretical technique employed for systematic inclusion of higher order QCD effects: one employed the POWHEG software, the other the MadGraph5_aMC@NLO one. Suppose we had a FullSim reference sample \\(REF_{Full}\\), we computed its FlashSim \\(REF_{Flash}\\) sample as well as that of another possible variation \\(VAR_{Flash}\\). We would expect that the actual \\(VAR_{Full}\\) may be re-obtained faster than a run of FullSim by the factorization:</p> \\[VAR_{Full} = REF_{Full} \\frac{VAR_{Flash}}{REF_{Flash}} \\] <p>as the ratio factors out the FlashSim differences and leaves out only the software sample differences which are then multiplied by the \\(REF_{Full}\\) sample. The following Figure shows that our expectations are met by the FlashSim approach, as the aMC@NLO FullSim variation sample agrees with the ratio calculated from the POWHEG variation sample and the aMC@NLO FlashSim sample. This opens up the way to fast calculations of theoretical variations starting only from a single, pre-existing FullSim sample, implying a considerable speed-up when compared to re-starting always from Gen-level, as it is currently the case.</p> <p></p>"},{"location":"results/#flashsim-vs-gen","title":"FlashSim vs Gen","text":"<p>In order to better understand the added value of FlashSim, we can compare its output to what could be achieved by working directly at the Gen-level. Part of the chosen selection analysis objects may in fact be computed starting from Gen-level information alone, and thus we can ask ourselves if the FlashSim results are significantly different from those obtained with its inputs, the Gen values. In the following, we compare results for the Signal sample considering the three samples of FullSim, FlashSim and Gen.</p> <p>For the \\(\\log(z^*)\\) angular distribution, as the angular resolution is already good at Gen level, and the next figure shows no significant deviations between the three samples. On the other hand, it should be noted that the fraction of events passing the selection (i.e. the integral of the plot) is much better reproduced in FlashSim than at Gen-level.</p> <p></p> <p>However, as we move to the \\(R(p_T)\\), which depends on the hadronic activity, and thus on the effect of the interaction and reconstruction in the detector, we see the expected differences, as plotted below:</p> <p></p> <p>Additionally, the importance of the interaction with the detector and of the reconstruction, leading to smearing in the distribution of the dimuon mass, is emphasized by the next figure, where we can see that the Gen has only a single, peaked value, while FlashSim has correctly learned the expected smearing.</p> <p></p> <p>Finally, this differences also translate to the distribution of the VBF DNN Output, which is the fitted observable in the final analysis, shown below:</p> <p></p>"},{"location":"results/#upsampling","title":"Upsampling","text":"<p>Because the simulation and reconstruction steps are currently much slower than the generation one, when working with FullSim the default choice is to employ a different Gen-level event for each passing through simulation and reconstruction, to maximize the information contained in the final dataset. As our proposed FlashSim has demonstrated significant speed improvements, we decided to experiment with upsampling; i.e. generating multiple final-state, NanoAOD-format events from the same Gen-level information. In practice, due to the stochasticity of the simulation step, we are computing the pdf of the reconstructed events for each Gen-event. </p> <p>The next Figureshows this is indeed the case: if we generate 10,000 events from the same Signal POWHEG Gen-level value we observe a distribution spread around the single value returned from the conventional, 1-to-1 FlashSim approach, at least for those variables having a strong dependency on experimental resolution, such as the VBF DNN Output. The \\(\\log(z^*)\\) is instead sharply peaked around the FullSim value, as it is very precisely reconstructed, hence the simulation+reconstruction value is very close to the generated one. The stochasticity introduced by the Sim step is closely related to the selected variable, and we expect more significant advantages for those variables presenting a good spreading.   It is also interesting to note that out of the 10,000 generated events only 7,633 pass the analysis selection and are being used to plot the VBF DNN Output distribution.</p> <p> </p> <p>The capacity for upsampling offers some important advantages. First of all, if FlashSim is capable of running at 33 kHz, the Gen production is becoming our bottleneck, hence reusing the Gen implies additional resource savings. Additionally, because we are generating more data, we can expect a reduction of the statistical error; however we must correctly compute the uncertainties in this case.</p> <p>Usually, if we are interested in finding the discrete pdf from an histogram, assuming a poisson statistics the pdf i-th bin and its error are defined as:</p> \\[   pdf_i = \\frac{\\sum_{ev \\in i}{w_{ev}}}{\\sum_{ev}{w_{ev}}}; \\quad        \\sigma_i = \\frac{\\sqrt{\\sum_{ev \\in i}{w_{ev}^2}}}{\\sum_{ev}{w_{ev}}} \\] <p>Where the ws are the weights for each event and they are typically set to 1.    In the upsampling case instead, we have N upsampled events with a common Gen-event (called folds), and thus we obtain:</p> \\[ pdf_i = \\frac{\\sum_{ev}\\sum_{fold\\in i}{w_{ev}}}{N_{fold}\\sum_{ev}{w_{ev}}} = \\frac{\\sum_{ev}\\sum_{fold\\in i}{w_{ev}/N_{fold}}}{\\sum_{ev}{w_{ev}}} = \\frac{\\sum_{ev}{w_{ev}pdf_i^{ev}}}{\\sum_{ev}{w_{ev}}} \\] <p>That is, each event may now enter multiple bins as it has been upsampled by a factor N--this is the same as saying that we can sum the pdf of each single event to obtain the final pdf. For the errors we consider folds from the same events entering different bins as uncorrelated, with a weight proportional to the number of folds entering the same bin. By recovering the initial error formula we get:</p> \\[ \\sigma_i = \\frac{\\sqrt{\\sum_{ev}(\\sum_{fold\\in i}{w_{ev}/N_{fold})^2}}}{\\sum_{ev}{w_{ev}}} =   \\frac{\\sqrt{\\sum_{ev}{(w_{ev}pdf_i^{ev})^2}}}{\\sum_{ev}{w_{ev}}} \\] <p>Practically speaking, for each event, we let the N upsampled events fill the histogram, and then defined the pdf of a single event as (bin content)/N, a quantity also used for determining the new statistical error. The resulting pdfs are then summed together to obtain the final histogram. This procedure is necessary to ensure that we are properly accounting for upsampled events filling the same bin--e.g. we want to have no difference between the 1-to-1 approach and the case where all events fill the same bin.</p> <p>As already discussed, we expect a greater reduction of the errors for those variables heavily influenced by the interaction with the detector.</p> <p>The following figure shows the comparison for the Signal POWHEG VBF DNN Output between the 1-to-1 FlashSim and the FlashSim upsampled by a factor of 25, whose histogram was filled with the empirical pdfs as described above. The mean statistical error (defined as the mean for the square of the sum of weights squared) is 32.3 for the first case, which gets reduced to 14.2 for the upsampled dataset; approximately by a factor of \\(1/2\\). The relative error, defined as the error per bin divided by the bin content, is also showed in the first lower panel and is clearly decreasing across all bins, while the ratio is approximately one, as expected. For variables reconstructed with very high resolution, i.e. when the simulation+reconstruction does not introduce any significant smearing, such as \\(\\log(z^*)\\), we observe a smaller error reduction (11.2 from 14.4), as expected.</p> <p> </p> <p>Another important advantage is that we may be able to obtain more smooth, convincing distributions for those cases where the low number of events is a limiting factor. One of such cases is the VBF DNN Output for the DY 2Jets dataset, which has high errors and a jagged distribution as only a tiny fraction of events pass the selection.</p> <p>By performing an upsampling by a factor of 25 and comparing the results, we immediately see below that the resulting upsampled VBF DNN Output distribution not only has lower errors, but also manages to produce a more smoothly decreasing and convincing distribution, without the jagged peaks given by the small sample size of the 1-to-1 case.</p> <p></p> <p>The results of the present Chapter demonstrate that not only is FlashSim capable of producing different distributions from those of the bare Gen-level, but also that it can come close to the results yield by FullSim. Additionally, it can fully make use of Gen-level information through the upsampling procedure.</p>"},{"location":"trainings/","title":"Trainings","text":""},{"location":"trainings/#a-brief-intro-to-normalizing-flows","title":"A brief intro to Normalizing Flows","text":"<p>Normalizing flows are a family of methods for constructing flexible learnable probability distributions, often with neural networks, which allow us to surpass the limitations of simple parametric forms to represent high-dimensional distributions. Our specific goal is to represent, in fact learn from data, the underlying \\(p^*_x(\\mathbf{x})\\) for our FullSim simulated samples \\(\\mathbf{x}\\) with this formalism, so that we may then draw new, original samples from it.</p>"},{"location":"trainings/#basics","title":"Basics","text":"<p>The basic idea is to define a multidimensional distribution \\(p_x(\\mathbf{x})\\) by passing random variables \\(\\mathbf{z} \\in \\mathbb{R}^D\\) drawn from a simple base distribution \\(p_z(\\mathbf{z})\\), typically a multi-dimensional Gaussian, through a non-linear, invertible and differentiable transformation f: \\(\\mathbb{R}^D \\rightarrow \\mathbb{R}^D\\), \\(\\mathbf{x} = f(\\mathbf{z})\\). f can also be called a bijection.</p> <p>Because \\(\\mathbf{x} = f(\\mathbf{z})\\), \\(p_x(\\mathbf{x})\\) can be expressed as:</p> \\[ p_x(\\mathbf{x}) = p_z(\\mathbf{z})\\det\\left|\\frac{d\\mathbf{z}}{d\\mathbf{x}}\\right| \\] <p>Intuitively, if we compose such bijective transformations, \\(f = (f_{(1)}\\circ f_{(2)}\\circ\\cdots\\circ f_{(K)})\\), we obtain more expressive transforms, thus being able to produce very complicated distributions. In order to do so, we would like to factorize the contribution of each single \\(f_i\\). Remembering that f is invertible, taking the logarithm of both sides we get:</p> \\[         \\log(p_x(x)) = \\log(p_z(f^{-1}(\\mathbf{x})))+\\log\\left(\\det\\left|\\frac{d\\mathbf{z}}{d\\mathbf{x}}\\right|\\right)         = \\log(p_z(f^{-1}(\\mathbf{x})))-\\log\\left(\\det\\left|\\frac{d\\mathbf{x}}{d\\mathbf{z}}\\right|\\right) \\] <p>where \\(d\\mathbf{z}/d\\mathbf{x}\\) denotes the Jacobian matrix of \\(f^{-1}(\\mathbf{x})\\), \\(\\mathbb{J}_{f^{-1}}(\\mathbf{x})\\). Intuitively, this equation says that the density of \\(x\\) is equal to the density at the corresponding point in \\(z\\) plus a term that corrects for the warp in volume around an infinitesimally small volume around \\(x\\) caused by the transformation.  It is clear that, if we have \\(K\\) transforms \\(f_{(1)}, f_{(2)},\\ldots,f_{(K)}\\), then the log-density of the transformed variable \\(\\mathbf{x}=(f_{(1)}\\circ f_{(2)}\\circ\\cdots\\circ f_{(K)})(\\mathbf{z})\\) is:</p> \\[             \\begin{aligned}             \\log(p_x(\\mathbf{x})) &amp;= \\log\\left(p_z\\left(\\left(f_{(K)}^{-1}\\circ\\cdots\\circ f_{(1)}^{-1}\\right)\\left(\\mathbf{x}\\right)\\right)\\right)+\\\\             &amp;+\\sum^{K}_{k=1}\\log\\left(\\left|\\frac{df^{-1}_{(k)}(\\mathbf{x}_{(k)})}{d\\mathbf{x}'}\\right|\\right)         \\end{aligned} \\] <p>This relationship between the base distribution and the transformed one through this chain of invertible transforms is at the core of the NF approach and is illustrated in the following figure: how can we find a chain of invertible transformations to send \\(p_z(\\mathbf{z})\\) to \\(p_x(\\mathbf{x})\\)? Taken from here.</p> <p></p> <p>Based on this, the idea is to define some kind of measure, which can then be used as the objective function to minimize, to learn the optimal transformation f for defining the target \\(p_x(\\mathbf{x})\\), so that sampling becomes as easy as sampling a multi-dimensional Gaussian.</p>"},{"location":"trainings/#loss-function","title":"Loss function","text":"<p>As the idea is to leverage deep learning, we let our transformation f depend on a set of learnable parameters \\(\\phi\\), \\(f = f(\\mathbf{x};\\, \\phi)\\). It should be noted that \\(\\phi\\) can actually be a learnable function of some parameters, rather than a constant. This will enable us to define conditional pdfs as we will see in the following.</p> <p>In our HEP case, we have billions of available Monte Carlo data and no analytical pdf \\(p_x^*(\\mathbf{x})\\). Then, we may define as our loss function the forward Kullback-Leibler divergence between the target distribution \\(p_x^*(\\mathbf{x})\\) and the flow-defined one \\(p_x(\\mathbf{x}; \\, \\phi)\\):</p> \\[     \\begin{aligned}     \\mathcal{L}(\\phi) &amp;= \\mathcal{D}_{KL}[p_x^*(\\mathbf{x})||p_x(\\mathbf{x}; \\, \\phi)]\\\\     &amp;= -\\mathbb{E}_{p_x^*(\\mathbf{x})}[\\log(p_x(\\mathbf{x}; \\, \\phi))] +\\; \\text{const.}\\\\     &amp;= -\\mathbb{E}_{p_x^*(\\mathbf{x})}[\\log(p_z(f^{-1}(\\mathbf{x}; \\, \\phi)))+\\log\\left(\\det\\mathbb{J}_{f^{-1}}(\\mathbf{x}; \\, \\phi)\\right)] +\\; \\text{const.}     \\end{aligned} \\] <p>Supposing we had a set of training samples \\(\\{\\mathbf{x}\\}^N_n\\) from the target pdf, we may estimate the expectation value over \\(p_x^*(\\mathbf{x})\\) by Monte Carlo as:</p> \\[ \\mathcal{L}(\\phi) \\approx -\\frac{1}{N} \\sum_n [\\log(p_z(f^{-1}(\\mathbf{x}_n; \\, \\phi)))+\\log\\left(\\det\\mathbb{J}_{f^{-1}}(\\mathbf{x}_n; \\, \\phi)\\right)] +\\; \\text{const.} \\] <p>Note that, in comparison with other generative models such as GANs, a decrease in the loss function actually implies an improvement in the performance of the model. For computing this loss we need to calculate \\(f^{-1}\\), its Jacobian determinant and the density \\(p_z(f^{-1}(\\mathbf{x}; \\, \\phi))\\).</p>"},{"location":"trainings/#coupling-layers","title":"Coupling layers","text":"<p>One simple way to reduce the computational complexity of the Jacobian is to introduce coupling layers.  We partition the input \\(\\mathbf{z} \\in \\mathbb{R}^D\\) at any step in the network, being it the original Gaussian input or the output of some \\(f_{i-1}\\), into two subsets \\((\\vec z_{1:d}, \\, \\vec z_{d+1:D}) \\in \\mathbb{R}^d \\times \\mathbb{R}^{D-d}\\), where d is an integer between 1 and D, and is usually taken as \\(\\lceil D/2 \\rceil\\). Then, at each step, the transformation \\(f_i\\) is defined as:</p> \\[ f_i(\\mathbf{z}; \\, \\phi) = f_i(\\vec z_{d+1:D}; \\, \\phi(\\vec z_{1:d})) \\] <p>that is, the single transformation acts only on a subset of the input, keeping the other part unchanged and using it as conditioning for the actual parameters. </p> <p>At the end, the two subset are joined together to form the input for the next layer; by applying permutations between the indexes we can ensure that eventually all values of the input get transformed. (Specifically, we point out that if we simply apply linear permutations and we chain a number of transformations equal to the input dimension, eventually each variable will be transformed based on the conditioning of all the other ones at some point in the network. This means that the total transform will learn to generate final values which are correctly correlated to those for the others.) But the greatest advantage is that now the single transformation depends only on one subset of inputs, and thus its Jacobian is block triangular:</p> \\[ \\mathbb{J}_{f}(\\mathbf{x}; \\, \\phi) =  \\begin{pmatrix} \\frac{\\partial \\vec x_{1:d}}{\\partial \\vec z_{1:d}} &amp; \\frac{\\partial \\vec x_{1:d}}{\\partial \\vec z_{d+1:D}}\\\\ \\frac{\\partial \\vec x_{d+1:D}}{\\partial \\vec z_{1:d}} &amp; \\frac{\\partial \\vec x_{d+1:D}}{\\partial \\vec z_{d+1:D}} \\end{pmatrix} = \\begin{pmatrix} \\mathbb{I} &amp; 0\\\\ A &amp; \\mathbb{J}^* \\end{pmatrix} \\] <p>The full Jacobian determinant can simply be calculated from the product of the diagonal elements of \\(\\mathbb{J}^*\\), which are simply the partial derivatives over (\\(d+1, \\dots D\\)). A similar reasoning holds for the Jacobian of the inverse. This significantly speeds up the calculations.</p>"},{"location":"trainings/#splines","title":"Splines","text":"<p>So far, we did not define the family of functions to use as our \\(f_i(\\vec z_{d+1:D}; \\, \\phi(\\vec z_{1:d}))\\). There are many possible bijections which one can use in building a NF. Recent advancements have demonstrated the suitability of rational-quadratic spline transforms (see Durkan et al.). </p> <p>A monotonic spline is a piecewise function consisting of K segments, where each segment is a simple function that is easy to invert. Specifically, given a set of K+1 input locations \\(l_{0}, \\dots, l_K\\) , the transformation is taken to be a simple monotonic function (e.g. a low-degree polynomial) in each interval [\\(l_{k}, l_{k+1}\\)], under the constraint that the K segments meet at the endpoints. Outside the interval [\\(l_{0}, l_K\\)], the transformer can default to a simple function such as the identity. Typically, the parameters \\(\\phi\\) of the transformations are the input locations,  the corresponding output locations and (depending on the type of spline) the derivatives (i.e. slopes) at \\(l_{0}, \\dots, l_K\\). An example is illustrated in the following figure:</p> <p></p> <p>Spline-based transformers are as fast to invert as to evaluate, while maintaining exact analytical invertibility. Evaluating or inverting a spline-based transformer is done by first locating the right segment--which can be done in \\(\\mathcal{O}\\)(log K) time using binary search\u2014and then evaluating or inverting that segment, which is assumed to be analytically tractable. By increasing the number of segments K, a spline-based transformer can be made arbitrarily flexible.</p>"},{"location":"trainings/#conditioning","title":"Conditioning","text":"<p>The theory of Normalizing Flows is also easily generalized to conditional distributions. We denote the variable to condition on by \\(C=\\mathbf{c}\\in\\mathbb{R}^M\\). A simple multivariate source of noise, for example a standard i.i.d. normal distribution, \\(\\mathbf{z}\\sim\\mathcal{N}(\\mathbf{0},I_{D\\times D})\\), is passed through a vector-valued bijection that also conditions on C, \\(f:\\mathbb{R}^D\\times\\mathbb{R}^M\\rightarrow\\mathbb{R}^D\\), to produce the more complex transformed variable \\(\\mathbf{x}=f(\\mathbf{z};\\, \\phi(C))\\). </p> <p>In practice, this is usually accomplished by making the parameters for a known normalizing flow bijection \\(f\\) the output of a neural network that inputs \\(\\mathbf{c}\\) as well as one of the subsets of the coupling layer. It is thus straightforward to condition event generation on some ground truth, e.g. the Monte Carlo Gen values of a specific event that we wish to simulate. For example, the reconstructed transverse momentum \\(p_T\\) for a jet is expected to be positively correlated to the Gen \\(p_T\\), as are its mass and other key quantities; so we pass the Gen values as inputs to \\(\\phi\\).</p>"},{"location":"trainings/#models","title":"Models","text":"<p>The following figure shows the final architectures for both jets and muons.  Where two numbers are separated by a slash, the first refers to the muons model, the second to the jets one.</p> <p></p> <p>The figure shows the final models employed in this work.  As discussed before, the full model is composed of a chain of individual spline transformations, which act on only half of the input space and take the remaining half as additional parameters. Each spline acts after the preceding one: only the first one takes the actual random noise as input, while the following ones act on the transformed output of the previous steps. The conditioning Gen-level variables are instead passed as input to each step. By having a number of transforms in the chain equal to the full input size, we can be sure that the transformation of each single variable will eventually depend on all the other ones (as at each step half of the inputs is taken as parameters) thus ensuring the correct correlations in the final outputs.</p> <p>For each spline, the inputs are permuted and then splitted in half, sending half as parameters and half as argument of the spline transform. The conditioning Gen-level variables y are sent as input to a complex 10 layer fully-connected residual network (a different one for each transform) which defines the parameters for the spline. Its most relevant hyperparameters are the hidden_dim, the number of nodes per hidden layer, set to 256 for the muons model and to 298 for the jets one, the n_bin, the number of bins for the spline, set to 128 for both models and the n_blocks set to 10 for both and defining the number of hidden layers.</p>"},{"location":"trainings/#key-training-concepts","title":"Key training concepts","text":"<p>The code for the training is commented (see the GitHub repo), thus you should be able to infer most of the steps from comments alone. This page serves to discuss the most relevant training facts and choices in terms of hyperparameters, and to point at possible improvements and variations.</p> <p>We trained on 5 millions jet/muons from the \\(t\\overline{t}\\) process and validated on 100k jets/muons. The typical training times on a V100 32gb GPU were about 5 days for both models.</p> <p>The most relevant hyperparameters are defined in the snippet below (for the jets model):</p> <pre><code>    # define hyperparams\n    lr = 1e-5\n    total_epochs = 600\n    batch_size = 2048\n\n    #stuff \n\n    # define additional model parameters\n    param_dict = {\n        \"num_transform_blocks\": 10,\n        \"activation\": \"relu\",\n        \"batch_norm\": True,\n        \"num_bins\": 128,\n        \"hidden_dim\": 298,\n    }\n\n    # create model\n    flow = create_NDE_model(17, 14, 17, param_dict)\n</code></pre> <p>We will proceed to list them with a brief explanation for the chosen value:</p> <ul> <li>The learning rate has been fixed to a relatively small value for two main reasons. Having 50+ millions of parameters for the full model, we wanted a smooth descent, without overshooting. A small value helped in this regard, however we experimented with values of around 0.001 and found that the model was still capable of convergence in way less epochs. However, letting the training go on longer with a lower lr resulted in better results regarding the conditioning (how the Gen-level information influences the outputs), a feature not captured by the loss. We thus left a smaller value than what's actually needed.</li> <li>Epochs and batch size have been guessed as reasonable values after a few initial trainings. With such a large training sample, a large batch size helped with both training speed and by providing a large number of events to average upon (useful for our loss)</li> <li>The param dict defines key quantities for our neural networks defining the single splines of the full NF model:</li> <li>number of transformation blocks: specifying how many layers the network should have;</li> <li>activation type: we found the ReLU reliable as always;</li> <li>batch normalization: we turned it on as it supposedly helps with large models such as ours;</li> <li>number of bins: how many bins should the spline defined by the neural network have. This is actually a key parameter, and we had massive improvements once we switched from low numbers to higher ones. We could experiment with increasing this number while reducing layers/blocks;</li> <li>The hidden dimension specify how many nodes per layer the network should have.</li> <li>Finally, while creating the full model we must specify three numbers: the input variables number, the conditioning variables number and the number of flow steps, specifying how many splines the full model should have. We went with the exact same number as the input parameters. Because of the linear permutations and the coupling split at each flow step, this meant that eventually all variables will be generated with the others as conditioning--an ideal scenario for ensuring good correlations.</li> </ul>"},{"location":"trainings/#dataset-classes","title":"Dataset classes","text":"<p>Remember that we trained on 5 millions of jets/muons. Because jets are numerous in our training process (\\(t\\overline{t}\\)), we used a simple dataset for jets as we needed to open just one file to access the whole 5 millions jets.</p> <pre><code>class MyDataset(Dataset):\n    \"\"\"Very simple Dataset for reading hdf5 data\n        This is way simpler than muons as we heve enough jets in a single file\n        Still, dataloading is a bottleneck even here\n    Args:\n        Dataset (Pytorch Dataset): Pytorch Dataset class\n    \"\"\"\n\n    def __init__(self, h5_paths, limit):\n\n        self.h5_paths = h5_paths\n        self._archives = [h5py.File(h5_path, \"r\") for h5_path in self.    h5_paths]\n        self._archives = None\n\n        y = self.archives[0][\"data\"][:limit, 0:14] # conditioning\n        x = self.archives[0][\"data\"][:limit, 14:31] # targets\n        self.x_train = torch.tensor(x, dtype=torch.float32)  # .to(device)\n        self.y_train = torch.tensor(y, dtype=torch.float32)  # .to(device)\n\n    @property\n    def archives(self):\n        if self._archives is None:  # lazy loading here!\n            self._archives = [h5py.File(h5_path, \"r\") for h5_path in self.h5_paths]\n        return self._archives\n\n    def __len__(self):\n        return len(self.y_train)\n    # trivial get item by index\n    def __getitem__(self, idx):\n        return self.x_train[idx], self.y_train[idx]\n</code></pre> <p>Because muons are more scarce, we actually had to open up multiple files during training to have at our disposal the 5 millions. The dataset is thus more complex:</p> <pre><code>class H5Dataset(Dataset):\n    \"\"\"Pytorch Dataset for reading input data from hdf5 files on disk\n    Expects hdf5 files containing a \"data\" Dataset, which in turn contains correctly processed data\n    (there is no preprocessing here), and returns two separate tensor for each instance\n    Uses np.searchsorted to getitems from different files (thanks @Nadya!)\n    However, dataloading is a current bottleneck and should be investigated\n    x: target variables (expects a 30:52 ordering on each row)\n    y: conditioning variables (expects a 0:30 ordering on each row)\n    Args:\n        Dataset (Pytorch Dataset): Pytorch Dataset class\n    \"\"\"\n\n    def __init__(self, h5_paths, limit=-1):\n        \"\"\"Initialize the class, set indexes across datasets and define lazy loading\n        Args:\n            h5_paths (strings): paths to the various hdf5 files to include in the final Dataset\n            limit (int, optional): optionally limit dataset length to specified values, if negative\n                returns the full length as inferred from files. Defaults to -1.\n        \"\"\"\n        max_events = int(5e9)\n        self.limit = max_events if limit == -1 else int(limit)\n        self.h5_paths = h5_paths\n        self._archives = [h5py.File(h5_path, \"r\") for h5_path in self.h5_paths]\n\n        self.strides = []\n        for archive in self.archives:\n            with archive as f:\n                self.strides.append(len(f[\"data\"])) \n\n        self.len_in_files = self.strides[1:]\n        self.strides = np.cumsum(self.strides)\n        self._archives = None\n\n    @property\n    def archives(self):\n        if self._archives is None:  # lazy loading here!\n            self._archives = [h5py.File(h5_path, \"r\") for h5_path in self.h5_paths]\n        return self._archives\n\n    # smart get item through searchsorted for finding the right file\n    # and getting the actual index in the file\n    def __getitem__(self, index):\n        file_idx = np.searchsorted(self.strides, index, side=\"right\")\n        idx_in_file = index - self.strides[max(0, file_idx - 1)]\n        y = self.archives[file_idx][\"data\"][idx_in_file, 0:30]\n        x = self.archives[file_idx][\"data\"][idx_in_file, 30:52]\n        y = torch.from_numpy(y)\n        x = torch.from_numpy(x)\n        # x = x.float()\n        # y = y.float()\n\n        return x, y\n\n    def __len__(self):\n        # return self.strides[-1] #this will process all files\n        if self.limit &lt;= self.strides[-1]:\n            return self.limit\n        else:\n            return self.strides[-1]\n</code></pre> <p>Despite the different approaches, we observed that the data loading step may actually be a severe bottleneck in our training as the GPU utilization heavily fluctuated between 40% and 70% most of the time. When we tried to implement a dataset similar to the muons' one for the jets we observed a significant slowdown, suggesting that the dataset classes may be part of the problem.</p>"},{"location":"trainings/#cosine-annealing","title":"Cosine annealing","text":"<p>It should be noted that the learning rate for both models was constantly updated through the cosine annealing procedure.</p> <p>Cosine Annealing is a type of learning rate schedule that has the effect of starting with a large learning rate that is relatively rapidly decreased to a minimum value before being increased rapidly again. The resetting of the learning rate acts like a simulated restart of the learning process and the re-use of good weights as the starting point of the restart is referred to as a warm restart in contrast to a cold restart where a new set of small random numbers may be used as a starting point. The proper formula is:</p> \\[\\eta_{t} = \\eta_{min} + \\frac{1}{2}\\left(\\eta_{max}-\\eta_{min}\\right)\\left(1+\\cos\\left(\\frac{T_{cur}}{T_{max}}\\pi\\right)\\right)\\] <p>were \\(\\eta\\) is the learning rate and \\(T\\) the training epoch.</p>"},{"location":"trainings/#training-losses","title":"Training losses","text":"<p>We show here the losses for both models during training. Please note that the validation loss has been averaged over the last 5 epochs.</p> <p></p> <p></p> <p>The jets model shows clear signs for improvements, but it was stopped because we had to put results together for my thesis. The muons models, on the other hand, shows signs of stalling after epoch 200, but it was left in training as this vastly improved conditioning, a performance not captured by our loss.</p>"}]}