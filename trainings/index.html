
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://francesco-vaselli.github.io/nfs/trainings/">
      
      
        <link rel="prev" href="../preprocessing/">
      
      
        <link rel="next" href="../generation/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.5">
    
    
      
        <title>Trainings - FlashSim</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.8608ea7d.min.css">
      
      
  
  
    
    
  
  
  <style>:root{--md-admonition-icon--warning:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 14h-2V9h2m0 9h-2v-2h2M1 21h22L12 2z"/></svg>');}</style>



    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#a-brief-intro-to-normalizing-flows" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="FlashSim" class="md-header__button md-logo" aria-label="FlashSim" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            FlashSim
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Trainings
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/francesco-vaselli/FlashSim" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    francesco-vaselli/FlashSim
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="FlashSim" class="md-nav__button md-logo" aria-label="FlashSim" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    FlashSim
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/francesco-vaselli/FlashSim" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    francesco-vaselli/FlashSim
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../preprocessing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Preprocessing
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Trainings
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Trainings
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#a-brief-intro-to-normalizing-flows" class="md-nav__link">
    <span class="md-ellipsis">
      A brief intro to Normalizing Flows
    </span>
  </a>
  
    <nav class="md-nav" aria-label="A brief intro to Normalizing Flows">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#basics" class="md-nav__link">
    <span class="md-ellipsis">
      Basics
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#loss-function" class="md-nav__link">
    <span class="md-ellipsis">
      Loss function
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coupling-layers" class="md-nav__link">
    <span class="md-ellipsis">
      Coupling layers
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#splines" class="md-nav__link">
    <span class="md-ellipsis">
      Splines
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conditioning" class="md-nav__link">
    <span class="md-ellipsis">
      Conditioning
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#models" class="md-nav__link">
    <span class="md-ellipsis">
      Models
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-training-concepts" class="md-nav__link">
    <span class="md-ellipsis">
      Key training concepts
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dataset-classes" class="md-nav__link">
    <span class="md-ellipsis">
      Dataset classes
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cosine-annealing" class="md-nav__link">
    <span class="md-ellipsis">
      Cosine annealing
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-losses" class="md-nav__link">
    <span class="md-ellipsis">
      Training losses
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Generation
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../results/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Results
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../about/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    About
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#a-brief-intro-to-normalizing-flows" class="md-nav__link">
    <span class="md-ellipsis">
      A brief intro to Normalizing Flows
    </span>
  </a>
  
    <nav class="md-nav" aria-label="A brief intro to Normalizing Flows">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#basics" class="md-nav__link">
    <span class="md-ellipsis">
      Basics
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#loss-function" class="md-nav__link">
    <span class="md-ellipsis">
      Loss function
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coupling-layers" class="md-nav__link">
    <span class="md-ellipsis">
      Coupling layers
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#splines" class="md-nav__link">
    <span class="md-ellipsis">
      Splines
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conditioning" class="md-nav__link">
    <span class="md-ellipsis">
      Conditioning
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#models" class="md-nav__link">
    <span class="md-ellipsis">
      Models
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-training-concepts" class="md-nav__link">
    <span class="md-ellipsis">
      Key training concepts
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dataset-classes" class="md-nav__link">
    <span class="md-ellipsis">
      Dataset classes
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cosine-annealing" class="md-nav__link">
    <span class="md-ellipsis">
      Cosine annealing
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-losses" class="md-nav__link">
    <span class="md-ellipsis">
      Training losses
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



  <h1>Trainings</h1>

<h2 id="a-brief-intro-to-normalizing-flows">A brief intro to Normalizing Flows</h2>
<p>Normalizing flows are a family of methods for constructing flexible learnable probability distributions, often with neural networks, which allow us to surpass the limitations of simple parametric forms to represent high-dimensional distributions. Our specific goal is to represent, in fact <em>learn from data</em>, the underlying <span class="arithmatex">\(p^*_x(\mathbf{x})\)</span> for our FullSim simulated samples <span class="arithmatex">\(\mathbf{x}\)</span> with this formalism, so that we may then draw new, original samples from it.</p>
<h3 id="basics">Basics</h3>
<p>The basic idea is to define a multidimensional distribution <span class="arithmatex">\(p_x(\mathbf{x})\)</span> by passing <em>random variables</em> <span class="arithmatex">\(\mathbf{z} \in \mathbb{R}^D\)</span> drawn from a simple <em>base distribution</em> <span class="arithmatex">\(p_z(\mathbf{z})\)</span>, typically a multi-dimensional Gaussian, through a non-linear, <em>invertible</em> and <em>differentiable</em> transformation <em>f</em>: <span class="arithmatex">\(\mathbb{R}^D \rightarrow \mathbb{R}^D\)</span>, <span class="arithmatex">\(\mathbf{x} = f(\mathbf{z})\)</span>. <em>f</em> can also be called a <em>bijection</em>.</p>
<p>Because <span class="arithmatex">\(\mathbf{x} = f(\mathbf{z})\)</span>, <span class="arithmatex">\(p_x(\mathbf{x})\)</span> can be expressed as:</p>
<div class="arithmatex">\[
p_x(\mathbf{x}) = p_z(\mathbf{z})\det\left|\frac{d\mathbf{z}}{d\mathbf{x}}\right|
\]</div>
<p>Intuitively, if we compose such bijective transformations, <span class="arithmatex">\(f = (f_{(1)}\circ f_{(2)}\circ\cdots\circ f_{(K)})\)</span>, we obtain more <em>expressive</em> transforms, thus being able to produce very complicated distributions. In order to do so, we would like to factorize the contribution of each single <span class="arithmatex">\(f_i\)</span>.
Remembering that <em>f</em> is invertible, taking the logarithm of both sides we get:</p>
<div class="arithmatex">\[
        \log(p_x(x)) = \log(p_z(f^{-1}(\mathbf{x})))+\log\left(\det\left|\frac{d\mathbf{z}}{d\mathbf{x}}\right|\right)
        = \log(p_z(f^{-1}(\mathbf{x})))-\log\left(\det\left|\frac{d\mathbf{x}}{d\mathbf{z}}\right|\right)
\]</div>
<p>where <span class="arithmatex">\(d\mathbf{z}/d\mathbf{x}\)</span> denotes the Jacobian matrix of <span class="arithmatex">\(f^{-1}(\mathbf{x})\)</span>, <span class="arithmatex">\(\mathbb{J}_{f^{-1}}(\mathbf{x})\)</span>.
Intuitively, this equation says that the density of <span class="arithmatex">\(x\)</span> is equal to the density at the corresponding point in <span class="arithmatex">\(z\)</span> plus a term that corrects for the warp in volume around an infinitesimally small volume around <span class="arithmatex">\(x\)</span> caused by the transformation.
 It is clear that, if we have <span class="arithmatex">\(K\)</span> transforms <span class="arithmatex">\(f_{(1)}, f_{(2)},\ldots,f_{(K)}\)</span>, then the log-density of the transformed variable <span class="arithmatex">\(\mathbf{x}=(f_{(1)}\circ f_{(2)}\circ\cdots\circ f_{(K)})(\mathbf{z})\)</span> is:</p>
<div class="arithmatex">\[
            \begin{aligned}
            \log(p_x(\mathbf{x})) &amp;= \log\left(p_z\left(\left(f_{(K)}^{-1}\circ\cdots\circ f_{(1)}^{-1}\right)\left(\mathbf{x}\right)\right)\right)+\\
            &amp;+\sum^{K}_{k=1}\log\left(\left|\frac{df^{-1}_{(k)}(\mathbf{x}_{(k)})}{d\mathbf{x}'}\right|\right)
        \end{aligned}
\]</div>
<p>This relationship between the base distribution and the transformed one through this chain of invertible transforms is at the core of the NF approach and is illustrated in the following figure: how can we find a chain of invertible transformations to send <span class="arithmatex">\(p_z(\mathbf{z})\)</span> to <span class="arithmatex">\(p_x(\mathbf{x})\)</span>? Taken from <a href="https://lilianweng.github.io/posts/2018-10-13-flow-models/" title="The figure source">here</a>.</p>
<p><img alt="The basic idea" src="../img/normalizing-flow.png" /></p>
<p>Based on this, the idea is to define some kind of measure, which can then be used as the objective function to minimize, to learn the optimal transformation <em>f</em> for defining the target <span class="arithmatex">\(p_x(\mathbf{x})\)</span>, so that sampling becomes as easy as sampling a multi-dimensional Gaussian.</p>
<h3 id="loss-function">Loss function</h3>
<p>As the idea is to leverage deep learning, we let our transformation <em>f</em> depend on a set of <em>learnable</em> parameters <span class="arithmatex">\(\phi\)</span>, <span class="arithmatex">\(f = f(\mathbf{x};\, \phi)\)</span>. It should be noted that <span class="arithmatex">\(\phi\)</span> can actually be a <em>learnable function</em> of some parameters, rather than a constant. This will enable us to define conditional pdfs as we will see in the following.</p>
<p>In our HEP case, we have billions of available Monte Carlo data and no analytical pdf <span class="arithmatex">\(p_x^*(\mathbf{x})\)</span>. Then, we may define as our loss function the <strong>forward Kullback-Leibler divergence</strong> between the target distribution <span class="arithmatex">\(p_x^*(\mathbf{x})\)</span> and the flow-defined one <span class="arithmatex">\(p_x(\mathbf{x}; \, \phi)\)</span>:</p>
<div class="arithmatex">\[
    \begin{aligned}
    \mathcal{L}(\phi) &amp;= \mathcal{D}_{KL}[p_x^*(\mathbf{x})||p_x(\mathbf{x}; \, \phi)]\\
    &amp;= -\mathbb{E}_{p_x^*(\mathbf{x})}[\log(p_x(\mathbf{x}; \, \phi))] +\; \text{const.}\\
    &amp;= -\mathbb{E}_{p_x^*(\mathbf{x})}[\log(p_z(f^{-1}(\mathbf{x}; \, \phi)))+\log\left(\det\mathbb{J}_{f^{-1}}(\mathbf{x}; \, \phi)\right)] +\; \text{const.}
    \end{aligned}
\]</div>
<p>Supposing we had a set of training samples <span class="arithmatex">\(\{\mathbf{x}\}^N_n\)</span> from the target pdf, we may estimate the expectation value over <span class="arithmatex">\(p_x^*(\mathbf{x})\)</span> by Monte Carlo as:</p>
<div class="arithmatex">\[
\mathcal{L}(\phi) \approx -\frac{1}{N} \sum_n [\log(p_z(f^{-1}(\mathbf{x}_n; \, \phi)))+\log\left(\det\mathbb{J}_{f^{-1}}(\mathbf{x}_n; \, \phi)\right)] +\; \text{const.}
\]</div>
<p>Note that, in comparison with other generative models such as GANs, a decrease in the loss function actually implies an improvement in the performance of the model.
For computing this loss we need to calculate <span class="arithmatex">\(f^{-1}\)</span>, its Jacobian determinant and the density <span class="arithmatex">\(p_z(f^{-1}(\mathbf{x}; \, \phi))\)</span>.</p>
<h3 id="coupling-layers">Coupling layers</h3>
<p>One simple way to reduce the computational complexity of the Jacobian is to introduce <em>coupling layers</em>. 
We partition the input <span class="arithmatex">\(\mathbf{z} \in \mathbb{R}^D\)</span> <em>at any step in the network</em>, being it the original Gaussian input or the output of some <span class="arithmatex">\(f_{i-1}\)</span>, into two subsets <span class="arithmatex">\((\vec z_{1:d}, \, \vec z_{d+1:D}) \in \mathbb{R}^d \times \mathbb{R}^{D-d}\)</span>, where <em>d</em> is an integer between 1 and <em>D</em>, and is usually taken as <span class="arithmatex">\(\lceil D/2 \rceil\)</span>. Then, at each step, the transformation <span class="arithmatex">\(f_i\)</span> is defined as:</p>
<div class="arithmatex">\[
f_i(\mathbf{z}; \, \phi) = f_i(\vec z_{d+1:D}; \, \phi(\vec z_{1:d}))
\]</div>
<p>that is, the single transformation acts only on a <em>subset</em> of the input, keeping the other part unchanged and using it as <em>conditioning</em> for the actual parameters. </p>
<p>At the end, the two subset are joined together to form the input for the next layer; by applying permutations between the indexes we can ensure that eventually all values of the input get transformed. (Specifically, we point out that if we simply apply <em>linear</em> permutations and we chain a number of transformations equal to the input dimension, eventually each variable will be transformed based on the conditioning of all the other ones at some point in the network. This means that the total transform will learn to generate final values which are correctly <em>correlated</em> to those for the others.)
But the greatest advantage is that now the single transformation depends only on one subset of inputs, and thus its Jacobian is <em>block triangular</em>:</p>
<div class="arithmatex">\[
\mathbb{J}_{f}(\mathbf{x}; \, \phi) = 
\begin{pmatrix}
\frac{\partial \vec x_{1:d}}{\partial \vec z_{1:d}} &amp; \frac{\partial \vec x_{1:d}}{\partial \vec z_{d+1:D}}\\
\frac{\partial \vec x_{d+1:D}}{\partial \vec z_{1:d}} &amp; \frac{\partial \vec x_{d+1:D}}{\partial \vec z_{d+1:D}}
\end{pmatrix}
=
\begin{pmatrix}
\mathbb{I} &amp; 0\\
A &amp; \mathbb{J}^*
\end{pmatrix}
\]</div>
<p>The full Jacobian determinant can simply be calculated from the product of the diagonal elements of <span class="arithmatex">\(\mathbb{J}^*\)</span>, which are simply the partial derivatives over (<span class="arithmatex">\(d+1, \dots D\)</span>). A similar reasoning holds for the Jacobian of the inverse.
This significantly speeds up the calculations.</p>
<h3 id="splines">Splines</h3>
<p>So far, we did not define the family of functions to use as our <span class="arithmatex">\(f_i(\vec z_{d+1:D}; \, \phi(\vec z_{1:d}))\)</span>.
There are many possible bijections which one can use in building a NF. Recent advancements have demonstrated the suitability of <em>rational-quadratic spline transforms</em> (see <a href="https://arxiv.org/abs/1906.04032" title="Ref paper">Durkan et al.</a>). </p>
<p>A monotonic spline is a piecewise function consisting of K segments, where each segment is a simple function that is easy to invert. Specifically, given a set of K+1 input locations <span class="arithmatex">\(l_{0}, \dots, l_K\)</span> , the transformation
is taken to be a simple monotonic function (e.g. a low-degree polynomial) in each interval
[<span class="arithmatex">\(l_{k}, l_{k+1}\)</span>], under the constraint that the K segments meet at the endpoints.
Outside the interval [<span class="arithmatex">\(l_{0}, l_K\)</span>], the transformer can default to a simple function such as the
identity. Typically, the parameters <span class="arithmatex">\(\phi\)</span> of the transformations are the input locations, 
the corresponding output locations and (depending on the type of spline) the
derivatives (i.e. slopes) at <span class="arithmatex">\(l_{0}, \dots, l_K\)</span>. An example is illustrated in the following figure:</p>
<p><img alt="The spline" src="../img/D9F0PDyWsAAWKHf.png" /></p>
<p>Spline-based transformers are as fast to invert as to evaluate, while
maintaining exact analytical invertibility. Evaluating or inverting a spline-based transformer
is done by first locating the right segment--which can be done in <span class="arithmatex">\(\mathcal{O}\)</span>(log K) time using binary
search—and then evaluating or inverting that segment, which is assumed to be analytically
tractable. By increasing the number of segments K, a spline-based transformer can be
made arbitrarily flexible.</p>
<h3 id="conditioning">Conditioning</h3>
<p>The theory of Normalizing Flows is also easily generalized to conditional distributions. We denote the variable to condition on by <span class="arithmatex">\(C=\mathbf{c}\in\mathbb{R}^M\)</span>. A simple multivariate source of noise, for example a standard i.i.d. normal distribution, <span class="arithmatex">\(\mathbf{z}\sim\mathcal{N}(\mathbf{0},I_{D\times D})\)</span>, is passed through a vector-valued bijection that also conditions on C, <span class="arithmatex">\(f:\mathbb{R}^D\times\mathbb{R}^M\rightarrow\mathbb{R}^D\)</span>, to produce the more complex transformed variable <span class="arithmatex">\(\mathbf{x}=f(\mathbf{z};\, \phi(C))\)</span>. </p>
<p>In practice, this is usually accomplished by making the parameters for a known normalizing flow bijection <span class="arithmatex">\(f\)</span> the output of a neural network that inputs <span class="arithmatex">\(\mathbf{c}\)</span> as well as one of the subsets of the coupling layer. It is thus straightforward to condition event generation on some ground truth, e.g. the Monte Carlo Gen values of a specific event that we wish to simulate. For example, the reconstructed transverse momentum <span class="arithmatex">\(p_T\)</span> for a jet is expected to be positively correlated to the Gen <span class="arithmatex">\(p_T\)</span>, as are its mass and other key quantities; so we pass the Gen values as inputs to <span class="arithmatex">\(\phi\)</span>.</p>
<h2 id="models">Models</h2>
<p>The following figure shows the final architectures for both jets and muons.  Where two numbers are separated by a slash, the first refers to the muons model, the second to the jets one.</p>
<p><img alt="The models" src="../img/nfmodel.png" /></p>
<p>The figure shows the final models employed in this work. 
As discussed before, the full model is composed of a <em>chain</em> of individual spline transformations, which act on only <em>half</em> of the input space and take the remaining half as additional parameters. Each spline acts after the preceding one: only the first one takes the actual random noise as input, while the following ones act on the transformed output of the previous steps. The <em>conditioning</em> Gen-level variables are instead passed as input to each step. By having a number of transforms in the chain equal to the full input size, we can be sure that the transformation of each single variable will eventually depend on all the other ones (as at each step half of the inputs is taken as parameters) thus ensuring the correct <em>correlations</em> in the final outputs.</p>
<p>For each spline, the inputs are permuted and then splitted in half, sending half as parameters and half as argument of the <em>spline transform</em>. The conditioning Gen-level variables <strong>y</strong> are sent as input to a complex 10 layer fully-connected <em>residual</em> network (a different one for each transform) which defines the parameters for the spline. Its most relevant hyperparameters are the <em>hidden_dim</em>, the number of nodes per hidden layer, set to 256 for the muons model and to 298 for the jets one, the <em>n_bin</em>, the number of bins for the spline, set to 128 for both models and the <em>n_blocks</em> set to 10 for both and defining the number of hidden layers.</p>
<h2 id="key-training-concepts">Key training concepts</h2>
<p>The code for the training is commented (see <a href="https://github.com/francesco-vaselli/FlashSim/tree/main/trainings" title="The git repo, training section">the GitHub repo</a>), thus you should be able to infer most of the steps from comments alone.
This page serves to discuss the most relevant training facts and choices in terms of hyperparameters, and to point at possible improvements and variations.</p>
<p>We trained on 5 millions jet/muons from the <span class="arithmatex">\(t\overline{t}\)</span> process and validated on 100k jets/muons. The typical training times on a V100 32gb GPU were about 5 days for both models.</p>
<p>The most relevant hyperparameters are defined in the snippet below (for the jets model):</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>    <span class="c1"># define hyperparams</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span class="n">lr</span> <span class="o">=</span> <span class="mf">1e-5</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span class="n">total_epochs</span> <span class="o">=</span> <span class="mi">600</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2048</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="c1">#stuff </span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="c1"># define additional model parameters</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="n">param_dict</span> <span class="o">=</span> <span class="p">{</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>        <span class="s2">&quot;num_transform_blocks&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>        <span class="s2">&quot;activation&quot;</span><span class="p">:</span> <span class="s2">&quot;relu&quot;</span><span class="p">,</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>        <span class="s2">&quot;batch_norm&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>        <span class="s2">&quot;num_bins&quot;</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>        <span class="s2">&quot;hidden_dim&quot;</span><span class="p">:</span> <span class="mi">298</span><span class="p">,</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>    <span class="p">}</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>    <span class="c1"># create model</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>    <span class="n">flow</span> <span class="o">=</span> <span class="n">create_NDE_model</span><span class="p">(</span><span class="mi">17</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">)</span>
</code></pre></div>
<p>We will proceed to list them with a brief explanation for the chosen value:</p>
<ul>
<li>The <em>learning rate</em> has been fixed to a relatively small value for two main reasons. Having 50+ millions of parameters for the full model, we wanted a smooth descent, without overshooting. A small value helped in this regard, however we experimented with values of around 0.001 and found that the model was still capable of convergence in way less epochs. However, letting the training go on longer with a lower lr resulted in better results regarding the <em>conditioning</em> (how the Gen-level information influences the outputs), a feature not captured by the loss. We thus left a smaller value than what's actually needed.</li>
<li><em>Epochs</em> and <em>batch size</em> have been guessed as reasonable values after a few initial trainings. With such a large training sample, a large batch size helped with both training speed and by providing a large number of events to average upon (useful for our loss)</li>
<li>The <em>param dict</em> defines key quantities for our neural networks defining the single <em>splines</em> of the full NF model:</li>
<li><em>number of transformation blocks</em>: specifying how many layers the network should have;</li>
<li><em>activation type</em>: we found the ReLU reliable as always;</li>
<li><em>batch normalization</em>: we turned it on as it supposedly helps with large models such as ours;</li>
<li><em>number of bins</em>: how many bins should the spline defined by the neural network have. This is actually a key parameter, and we had massive improvements once we switched from low numbers to higher ones. <strong>We could experiment with increasing this number while reducing layers/blocks</strong>;</li>
<li>The <em>hidden dimension</em> specify how many nodes per layer the network should have.</li>
<li>Finally, while creating the full model we must specify three numbers: the input variables number, the conditioning variables number and the <em>number of flow steps</em>, specifying how many splines the full model should have. We went with the exact same number as the input parameters. Because of the linear permutations and the coupling split at each flow step, this meant that eventually all variables will be generated with the others as conditioning--an ideal scenario for ensuring good correlations.</li>
</ul>
<h2 id="dataset-classes">Dataset classes</h2>
<p>Remember that we trained on 5 millions of jets/muons. Because jets are numerous in our training process (<span class="arithmatex">\(t\overline{t}\)</span>), we used a simple dataset for jets as we needed to open just one file to access the whole 5 millions jets.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="k">class</span><span class="w"> </span><span class="nc">MyDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Very simple Dataset for reading hdf5 data</span>
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="sd">        This is way simpler than muons as we heve enough jets in a single file</span>
<a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a><span class="sd">        Still, dataloading is a bottleneck even here</span>
<a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a><span class="sd">    Args:</span>
<a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a><span class="sd">        Dataset (Pytorch Dataset): Pytorch Dataset class</span>
<a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a>
<a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">h5_paths</span><span class="p">,</span> <span class="n">limit</span><span class="p">):</span>
<a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a>
<a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">h5_paths</span> <span class="o">=</span> <span class="n">h5_paths</span>
<a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_archives</span> <span class="o">=</span> <span class="p">[</span><span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">h5_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">h5_path</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span>    <span class="n">h5_paths</span><span class="p">]</span>
<a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_archives</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a>
<a id="__codelineno-1-15" name="__codelineno-1-15" href="#__codelineno-1-15"></a>        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">archives</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;data&quot;</span><span class="p">][:</span><span class="n">limit</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">14</span><span class="p">]</span> <span class="c1"># conditioning</span>
<a id="__codelineno-1-16" name="__codelineno-1-16" href="#__codelineno-1-16"></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">archives</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;data&quot;</span><span class="p">][:</span><span class="n">limit</span><span class="p">,</span> <span class="mi">14</span><span class="p">:</span><span class="mi">31</span><span class="p">]</span> <span class="c1"># targets</span>
<a id="__codelineno-1-17" name="__codelineno-1-17" href="#__codelineno-1-17"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">x_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># .to(device)</span>
<a id="__codelineno-1-18" name="__codelineno-1-18" href="#__codelineno-1-18"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">y_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># .to(device)</span>
<a id="__codelineno-1-19" name="__codelineno-1-19" href="#__codelineno-1-19"></a>
<a id="__codelineno-1-20" name="__codelineno-1-20" href="#__codelineno-1-20"></a>    <span class="nd">@property</span>
<a id="__codelineno-1-21" name="__codelineno-1-21" href="#__codelineno-1-21"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">archives</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-1-22" name="__codelineno-1-22" href="#__codelineno-1-22"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_archives</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># lazy loading here!</span>
<a id="__codelineno-1-23" name="__codelineno-1-23" href="#__codelineno-1-23"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_archives</span> <span class="o">=</span> <span class="p">[</span><span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">h5_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">h5_path</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">h5_paths</span><span class="p">]</span>
<a id="__codelineno-1-24" name="__codelineno-1-24" href="#__codelineno-1-24"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_archives</span>
<a id="__codelineno-1-25" name="__codelineno-1-25" href="#__codelineno-1-25"></a>
<a id="__codelineno-1-26" name="__codelineno-1-26" href="#__codelineno-1-26"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-1-27" name="__codelineno-1-27" href="#__codelineno-1-27"></a>        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_train</span><span class="p">)</span>
<a id="__codelineno-1-28" name="__codelineno-1-28" href="#__codelineno-1-28"></a>    <span class="c1"># trivial get item by index</span>
<a id="__codelineno-1-29" name="__codelineno-1-29" href="#__codelineno-1-29"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
<a id="__codelineno-1-30" name="__codelineno-1-30" href="#__codelineno-1-30"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_train</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
</code></pre></div>
<p>Because muons are more scarce, we actually had to open up multiple files during training to have at our disposal the 5 millions. The dataset is thus more complex:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="k">class</span><span class="w"> </span><span class="nc">H5Dataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Pytorch Dataset for reading input data from hdf5 files on disk</span>
<a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="sd">    Expects hdf5 files containing a &quot;data&quot; Dataset, which in turn contains correctly processed data</span>
<a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span class="sd">    (there is no preprocessing here), and returns two separate tensor for each instance</span>
<a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a><span class="sd">    Uses np.searchsorted to getitems from different files (thanks @Nadya!)</span>
<a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a><span class="sd">    However, dataloading is a current bottleneck and should be investigated</span>
<a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a><span class="sd">    x: target variables (expects a 30:52 ordering on each row)</span>
<a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a><span class="sd">    y: conditioning variables (expects a 0:30 ordering on each row)</span>
<a id="__codelineno-2-9" name="__codelineno-2-9" href="#__codelineno-2-9"></a><span class="sd">    Args:</span>
<a id="__codelineno-2-10" name="__codelineno-2-10" href="#__codelineno-2-10"></a><span class="sd">        Dataset (Pytorch Dataset): Pytorch Dataset class</span>
<a id="__codelineno-2-11" name="__codelineno-2-11" href="#__codelineno-2-11"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-2-12" name="__codelineno-2-12" href="#__codelineno-2-12"></a>
<a id="__codelineno-2-13" name="__codelineno-2-13" href="#__codelineno-2-13"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">h5_paths</span><span class="p">,</span> <span class="n">limit</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>
<a id="__codelineno-2-14" name="__codelineno-2-14" href="#__codelineno-2-14"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the class, set indexes across datasets and define lazy loading</span>
<a id="__codelineno-2-15" name="__codelineno-2-15" href="#__codelineno-2-15"></a><span class="sd">        Args:</span>
<a id="__codelineno-2-16" name="__codelineno-2-16" href="#__codelineno-2-16"></a><span class="sd">            h5_paths (strings): paths to the various hdf5 files to include in the final Dataset</span>
<a id="__codelineno-2-17" name="__codelineno-2-17" href="#__codelineno-2-17"></a><span class="sd">            limit (int, optional): optionally limit dataset length to specified values, if negative</span>
<a id="__codelineno-2-18" name="__codelineno-2-18" href="#__codelineno-2-18"></a><span class="sd">                returns the full length as inferred from files. Defaults to -1.</span>
<a id="__codelineno-2-19" name="__codelineno-2-19" href="#__codelineno-2-19"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-2-20" name="__codelineno-2-20" href="#__codelineno-2-20"></a>        <span class="n">max_events</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">5e9</span><span class="p">)</span>
<a id="__codelineno-2-21" name="__codelineno-2-21" href="#__codelineno-2-21"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">limit</span> <span class="o">=</span> <span class="n">max_events</span> <span class="k">if</span> <span class="n">limit</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span> <span class="k">else</span> <span class="nb">int</span><span class="p">(</span><span class="n">limit</span><span class="p">)</span>
<a id="__codelineno-2-22" name="__codelineno-2-22" href="#__codelineno-2-22"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">h5_paths</span> <span class="o">=</span> <span class="n">h5_paths</span>
<a id="__codelineno-2-23" name="__codelineno-2-23" href="#__codelineno-2-23"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_archives</span> <span class="o">=</span> <span class="p">[</span><span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">h5_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">h5_path</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">h5_paths</span><span class="p">]</span>
<a id="__codelineno-2-24" name="__codelineno-2-24" href="#__codelineno-2-24"></a>
<a id="__codelineno-2-25" name="__codelineno-2-25" href="#__codelineno-2-25"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">strides</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-2-26" name="__codelineno-2-26" href="#__codelineno-2-26"></a>        <span class="k">for</span> <span class="n">archive</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">archives</span><span class="p">:</span>
<a id="__codelineno-2-27" name="__codelineno-2-27" href="#__codelineno-2-27"></a>            <span class="k">with</span> <span class="n">archive</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
<a id="__codelineno-2-28" name="__codelineno-2-28" href="#__codelineno-2-28"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">strides</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">f</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">]))</span> 
<a id="__codelineno-2-29" name="__codelineno-2-29" href="#__codelineno-2-29"></a>
<a id="__codelineno-2-30" name="__codelineno-2-30" href="#__codelineno-2-30"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">len_in_files</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strides</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
<a id="__codelineno-2-31" name="__codelineno-2-31" href="#__codelineno-2-31"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">strides</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">strides</span><span class="p">)</span>
<a id="__codelineno-2-32" name="__codelineno-2-32" href="#__codelineno-2-32"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_archives</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-2-33" name="__codelineno-2-33" href="#__codelineno-2-33"></a>
<a id="__codelineno-2-34" name="__codelineno-2-34" href="#__codelineno-2-34"></a>    <span class="nd">@property</span>
<a id="__codelineno-2-35" name="__codelineno-2-35" href="#__codelineno-2-35"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">archives</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-2-36" name="__codelineno-2-36" href="#__codelineno-2-36"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_archives</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># lazy loading here!</span>
<a id="__codelineno-2-37" name="__codelineno-2-37" href="#__codelineno-2-37"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_archives</span> <span class="o">=</span> <span class="p">[</span><span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">h5_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">h5_path</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">h5_paths</span><span class="p">]</span>
<a id="__codelineno-2-38" name="__codelineno-2-38" href="#__codelineno-2-38"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_archives</span>
<a id="__codelineno-2-39" name="__codelineno-2-39" href="#__codelineno-2-39"></a>
<a id="__codelineno-2-40" name="__codelineno-2-40" href="#__codelineno-2-40"></a>    <span class="c1"># smart get item through searchsorted for finding the right file</span>
<a id="__codelineno-2-41" name="__codelineno-2-41" href="#__codelineno-2-41"></a>    <span class="c1"># and getting the actual index in the file</span>
<a id="__codelineno-2-42" name="__codelineno-2-42" href="#__codelineno-2-42"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
<a id="__codelineno-2-43" name="__codelineno-2-43" href="#__codelineno-2-43"></a>        <span class="n">file_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">strides</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">side</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">)</span>
<a id="__codelineno-2-44" name="__codelineno-2-44" href="#__codelineno-2-44"></a>        <span class="n">idx_in_file</span> <span class="o">=</span> <span class="n">index</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">strides</span><span class="p">[</span><span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">file_idx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span>
<a id="__codelineno-2-45" name="__codelineno-2-45" href="#__codelineno-2-45"></a>        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">archives</span><span class="p">[</span><span class="n">file_idx</span><span class="p">][</span><span class="s2">&quot;data&quot;</span><span class="p">][</span><span class="n">idx_in_file</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">30</span><span class="p">]</span>
<a id="__codelineno-2-46" name="__codelineno-2-46" href="#__codelineno-2-46"></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">archives</span><span class="p">[</span><span class="n">file_idx</span><span class="p">][</span><span class="s2">&quot;data&quot;</span><span class="p">][</span><span class="n">idx_in_file</span><span class="p">,</span> <span class="mi">30</span><span class="p">:</span><span class="mi">52</span><span class="p">]</span>
<a id="__codelineno-2-47" name="__codelineno-2-47" href="#__codelineno-2-47"></a>        <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<a id="__codelineno-2-48" name="__codelineno-2-48" href="#__codelineno-2-48"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-2-49" name="__codelineno-2-49" href="#__codelineno-2-49"></a>        <span class="c1"># x = x.float()</span>
<a id="__codelineno-2-50" name="__codelineno-2-50" href="#__codelineno-2-50"></a>        <span class="c1"># y = y.float()</span>
<a id="__codelineno-2-51" name="__codelineno-2-51" href="#__codelineno-2-51"></a>
<a id="__codelineno-2-52" name="__codelineno-2-52" href="#__codelineno-2-52"></a>        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>
<a id="__codelineno-2-53" name="__codelineno-2-53" href="#__codelineno-2-53"></a>
<a id="__codelineno-2-54" name="__codelineno-2-54" href="#__codelineno-2-54"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-2-55" name="__codelineno-2-55" href="#__codelineno-2-55"></a>        <span class="c1"># return self.strides[-1] #this will process all files</span>
<a id="__codelineno-2-56" name="__codelineno-2-56" href="#__codelineno-2-56"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">limit</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strides</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
<a id="__codelineno-2-57" name="__codelineno-2-57" href="#__codelineno-2-57"></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">limit</span>
<a id="__codelineno-2-58" name="__codelineno-2-58" href="#__codelineno-2-58"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-2-59" name="__codelineno-2-59" href="#__codelineno-2-59"></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">strides</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</code></pre></div>
<p>Despite the different approaches, we observed that <strong>the data loading step may actually be a severe bottleneck in our training</strong> as the GPU utilization heavily fluctuated between 40% and 70% most of the time. When we tried to implement a dataset similar to the muons' one for the jets we observed a significant slowdown, suggesting that the dataset classes may be part of the problem.</p>
<h2 id="cosine-annealing">Cosine annealing</h2>
<p>It should be noted that the learning rate for both models was constantly updated through the <em>cosine annealing</em> procedure.</p>
<p>Cosine Annealing is a type of learning rate schedule that has the effect of starting with a large learning rate that is relatively rapidly decreased to a minimum value before being increased rapidly again. The resetting of the learning rate acts like a simulated restart of the learning process and the re-use of good weights as the starting point of the restart is referred to as a <em>warm restart</em> in contrast to a <em>cold restart</em> where a new set of small random numbers may be used as a starting point. The proper formula is:</p>
<div class="arithmatex">\[\eta_{t} = \eta_{min} + \frac{1}{2}\left(\eta_{max}-\eta_{min}\right)\left(1+\cos\left(\frac{T_{cur}}{T_{max}}\pi\right)\right)\]</div>
<p>were <span class="arithmatex">\(\eta\)</span> is the learning rate and <span class="arithmatex">\(T\)</span> the training epoch.</p>
<h2 id="training-losses">Training losses</h2>
<p>We show here the losses for both models during training. Please note that the validation loss has been averaged over the last 5 epochs.</p>
<p><img alt="The jets loss" src="../img/lossesjets.png" /></p>
<p><img alt="The muons loss" src="../img/lossesmuons.png" /></p>
<p>The jets model shows clear signs for improvements, but it was stopped because we had to put results together for my thesis. The muons models, on the other hand, shows signs of stalling after epoch 200, but it was left in training as this vastly improved <em>conditioning</em>, a performance not captured by our loss.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.f1b6f286.min.js"></script>
      
        <script src="../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>